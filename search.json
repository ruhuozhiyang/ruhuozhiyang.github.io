[{"title":"ES Scroll Query","date":"2023-11-05T05:44:20.834Z","url":"/2023/11/05/hadoop_ext/es/basic_concepts/es_scroll_query/","categories":[["hadoop_ext","/categories/hadoop-ext/"],["es","/categories/hadoop-ext/es/"],["es_basic_concepts","/categories/hadoop-ext/es/es-basic-concepts/"]],"content":"Scroll 查询｜深度分页Scroll 查询可以用来对 Elasticsearch 有效地执行大批量的文档查询，而又不用付出深度分页那种代价。"},{"title":"ES Term and Match Query","date":"2023-11-05T05:35:30.970Z","url":"/2023/11/05/hadoop_ext/es/basic_concepts/es_term&match/","categories":[["hadoop_ext","/categories/hadoop-ext/"],["es","/categories/hadoop-ext/es/"],["es_basic_concepts","/categories/hadoop-ext/es/es-basic-concepts/"]],"content":"Term Query代表完全匹配，也就是精确查询，搜索前不会再对搜索词进行分词解析，直接对搜索词进行查找；主要用于精确搜索精确搜索相较match模糊查询而言，效率较高 Match Query代表模糊匹配，搜索前会对搜索词进行分词解析，然后按分词匹配查找；主要用于模糊搜索 1.2. Hits 数组Hits数组默认返回10个。"},{"title":"Notes about Paper-Writing","date":"2023-11-03T17:04:04.376Z","url":"/2023/11/04/academic_research/paper_writing_notes/","categories":[["academic_research","/categories/academic-research/"]],"content":"1.研究生学术能力构成 2.论文的类型 学位论文 期刊&#x2F;会议论文 研究型论文 应用型论文 综述型论文 数据型论文 3.论文价值的甄别 盲区：前人没有发现的研究领域 科学研究的本质在于探索和创新 论文的创新性 误区：前人研究过的但是不准确或不科学的领域 疑区：前人研究过的但还存在一些疑问的领域 4.发现有价值的选题5.论文写作的 20 个步骤6.论文写作中存在的问题 问题 详情 选题过大、过难、创新性不够 研究方法落后或者不科学 研究材料陈旧或者不足 立论不够严谨 简单的工具、模型应用或套用 将经验介绍、工作总结、调研（实验）报告等同于研究论文 经验介绍：工作中取得的进展与成绩； 工作总结：工作过程与结果的描述； 调研报告：调研结果的总结与分析； 研究论文：提出问题、分析问题、解决问题； "},{"title":"ES Mapping","date":"2023-10-24T12:48:35.847Z","url":"/2023/10/24/hadoop_ext/es/basic_concepts/es_mapping/","categories":[["hadoop_ext","/categories/hadoop-ext/"],["es","/categories/hadoop-ext/es/"],["es_basic_concepts","/categories/hadoop-ext/es/es-basic-concepts/"]]},{"title":"ES Time Format","date":"2023-10-24T12:46:16.742Z","url":"/2023/10/24/hadoop_ext/es/basic_concepts/es_time_format/","categories":[["hadoop_ext","/categories/hadoop-ext/"],["es","/categories/hadoop-ext/es/"],["es_basic_concepts","/categories/hadoop-ext/es/es-basic-concepts/"]],"content":"1.时间格式ElasticSearch 默认的时间存储格式是 UTC 时间格式。当存储的 timestamp 是 UTC+8 时间格式时，即 当进行如下时间范围查询时，查询的是默认的 UTC 时间，即 2019-05-09T18:25:01.000+0000，转化为 UTC+8 时间格式为：2019-05-10T04:25:01.000+0800。 所以查询不到任何数据。需要进行如下格式的时间范围查询，查询的就是 UTC+8 格式的时间，所以可以查到数据。 "},{"title":"Character Encoding","date":"2023-10-23T09:28:03.735Z","url":"/2023/10/23/basic_concepts/character_encoding/","categories":[["basic_concepts","/categories/basic-concepts/"]],"content":"字符集，也称为字符编码或字符库，是计算机系统和通信协议中使用的字符及其相应数字表示的标准化集合。它定义了字符及其二进制表示之间的映射，允许计算机表示、存储和交换文本数据。 1.ASCII 字符集最常用的字符集是 ASCII（美国信息交换标准代码），它包括一组 128 个字符，代表基本的拉丁字母、数字、标点符号和控制字符。ASCII 码使用 7 位二进制来表示每个字符。随着技术的进步和支持更多字符的需求出现，在 ASCII 基础上扩展的各种字符集被开发出来以适应不同的语言和书写系统。 2.ISO-8859 字符集2.Unicode 字符集Unicode 是一种通用的字符编码标准，旨在涵盖世界上所有书写系统中的所有字符。它为每个字符分配一个唯一的数值，称为码位。Unicode 可以使用不同的编码方案实现，如 UTF-8、UTF-16 和 UTF-32。 3.GBK 字符集"},{"title":"File Type/Format","date":"2023-10-23T09:22:00.940Z","url":"/2023/10/23/basic_concepts/file_format/","categories":[["basic_concepts","/categories/basic-concepts/"]],"content":"1.系统资源&#x2F;资源在计算中，系统资源或资源是计算机系统中【可用性有限的】任何物理或虚拟组件。所有连接的设备和内部的系统组件都是资源。虚拟系统资源包括： 文件（具体来说是文件句柄） 网络连接（具体来说是网络套接字） 内存区域管理资源被称为资源管理，包括防止资源泄漏（当一个进程用完资源时不释放资源）和处理资源争用（当多个进程希望访问有限的资源时）。 2.计算机文件在计算中，计算机文件是用于在计算机存储设备上记录数据的资源，主要通过其文件名来标识。正如文字可以写在纸上一样，数据也可以写在计算机文件中。文件可以通过可移动介质、网络或互联网在计算机和移动设备之间共享和传输。不同类型的计算机文件是为不同的目的而设计的。文件可以被设计成存储图像、书面消息、视频、程序或任何种类的其他数据。某些文件可以一次存储多种数据类型。通过使用计算机程序，人们可以打开、读取、更改、保存和关闭计算机文件。计算机文件可以被重新打开、修改和复制任意次数。文件通常组织在文件系统中，该系统跟踪磁盘上的文件位置并允许用户访问。 在大多数现代操作系统上，文件被组织成一维数组字节数组。文件的格式由其内容定义，因为文件只是数据的容器。在某些平台上，格式由其文件扩展名表示，指定了字节必须如何有意义地组织和解释的规则。例如，纯文本文件的字节数据（Windows中的txt）与ASCII或UTF-8字符相关联，而图像、视频和音频文件的字节则以其他方式解释。大多数文件类型还为元数据分配了几个字节，这允许文件携带一些关于自身的基本信息。 一些文件系统可以存储文件格式之外的任意（不由文件系统解释）特定于文件的数据，但链接到文件，例如扩展属性或分叉。然而，所有这些方法都比容器和归档文件格式更容易丢失元数据。 3.文件类型&#x2F;格式文件格式是将信息编码存储在计算机文件中的标准方式。它规定了如何使用位对数字存储介质中的信息进行编码。文件格式可以是专有的，也可以是免费的。例如以下一些常见的文件类型： 二进制文件（Binary File）基于值编码的文件，可以根据具体应用，指定某个值（可以看作是自定义编码）。二进制文件可看成是变长编码的，因为是值编码，多少个比特代表一个值，完全由自己决定。 文本文件（Text File）基于字符编码的文件，常见的字符编码有 ASCII 编码，UNICODE 编码等等。文本文件基本上是定长编码的(也有非定长的编码如UTF-8)，基于字符，每个字符在具体编码中是固定的，ASCII码是8个比特的编码，UNICODE一般占16个比特。 位图文件（BitMap File） 不管什么类型的文件，其实本质上都是 01 二进制数据，而文件类型正是规定了这些 01 数据的正确解码方式。例如，对于如下的二进制序列 二进制文件只会将其看作是一些数，例如可以4位为一组，将序列分成若干组，并转为 16 进制数 还可以 3 位为一组，将序列分成若干组（多出一个 bit 忽略），并转为 8 进制数 二进制文件仅止步于此。 但是文本文件会基于字符编码进一步解析文件内容。例如基于 ASCII 编码（一个字节为分组，且其十进制值对应一个字符）来解析该二进制数据 位图文件则会依据一定的解码规则，将二进制序列分组，并得到一些十进制数，且将这些十进制数看作是像素值。 4.文件编辑器文件编辑器，我认为就是：（1）文件中 01 数据 &#x3D;&gt; 按文件格式正确解码 &#x3D;&gt; 用户可读（2）用户输入 &#x3D;&gt; 按文件格式正确编码 &#x3D;&gt; 文件中 01 数据所以，不同的文件格式就需要有相应的文件编辑器。 二进制文件编辑器 文本文件编辑器，例如 vim 位图文件编辑器 5.文本文件 纯文本 富文本文本文件是一种容器，而纯文本是指一种内容，文本文件可以包含纯文本。除了纯文本外，还有富文本，前者如记事本，后者如 Word。 纯文本只有文字和基本的标点，不保存文字的样式等，例如：.txt。 富文本可以有图和各种特殊标点，分段等格式，例如 .doc .docx 等。 6.文本 字符串字符串是用于存储和处理文本数据的数据类型，而文本则是由字符串组成的有意义的语言表达。在计算机科学和自然语言处理中，字符串和文本密不可分，相互依存，常常需要使用字符串操作来处理和操作文本数据。"},{"title":"ES text and keyword","date":"2023-10-23T08:25:39.434Z","url":"/2023/10/23/hadoop_ext/es/basic_concepts/es_keyword&text/","categories":[["hadoop_ext","/categories/hadoop-ext/"],["es","/categories/hadoop-ext/es/"],["es_basic_concepts","/categories/hadoop-ext/es/es-basic-concepts/"]],"content":"text and keyword2.x 版本里文本使用的是 string 字段。5.0 之后版本，string 字段过时，引入 keyword 和 text 字段，都可以用来存储字符串。text 字段用于全文搜索，keyword 字段用于结构化搜索。在新版本中，如果没有自己创建 mapping，那么在处理文本时，会把文本自动映射为”text”，同时会生成一个子字段”keyword”，类型是”keyword”。 在存储上，text 会被分词器进行分词，而 keyword 会被原样保留。比如 “Rabit is jumping”，text 的情况下可能被存储为 “rabit”，”jump”，而 keyword 情况下就会存储为 “Rabit is jumping”。 参考资料  "},{"title":"ElasticSearch Problems","date":"2023-10-23T08:21:18.451Z","url":"/2023/10/23/hadoop_ext/es/es_problems/","categories":[["hadoop_ext","/categories/hadoop-ext/"],["es","/categories/hadoop-ext/es/"],["es_advanced","/categories/hadoop-ext/es/es-advanced/"]]},{"title":"HBase Region In Transition","date":"2023-10-23T03:08:29.212Z","url":"/2023/10/23/hadoop/hbase/basic_concepts/hbase_region_in_transition/","categories":[["hadoop","/categories/hadoop/"],["hbase","/categories/hadoop/hbase/"],["hbase_basic_concepts","/categories/hadoop/hbase/hbase-basic-concepts/"]],"content":"1.Region-In-Trasition机制从字面意思来看，Region-In-Transition说的是Region变迁机制，实际上是指在一次特定操作行为中Region状态的变迁，例如merge、split、assign、unssign等操作。RIT问题指的是在RIT过程中出现异常情况，然后导致region的状态一直保持在RIT，使得HBase出现异常。 2.HBase2.0变化Region 的 RIT 状态不再由 ZooKeeper 参与，而是只由 HMaster 和 RegionServer 管理。 RIT 存在问题，例如 region 处于 opening 状态，region 是无法提供服务，是无法使用的。同时，region 存在问题是会影响 hbase 的均衡操作的，hbase是不会进行 region 均衡操作的。是否能自动检测表的哪些region不在线，光看master web UI 不靠谱 不准确。 3.瞬时 永久 RIT⼀般 RIT 都是瞬时的，但是有些情况会让其进入永久 RIT 状态，永久 RIT 状态带来的不良后果就是管理员无法干预 Region 均衡操作，从而影响集群的负载均衡。"},{"title":"HBase HFile Compaction","date":"2023-10-22T14:32:44.499Z","url":"/2023/10/22/hadoop/hbase/basic_concepts/hbase_compaction/","categories":[["hadoop","/categories/hadoop/"],["hbase","/categories/hadoop/hbase/"],["hbase_basic_concepts","/categories/hadoop/hbase/hbase-basic-concepts/"]]},{"title":"HBase Data Consistency Problem","date":"2023-10-22T14:29:40.188Z","url":"/2023/10/22/hadoop/hbase/basic_concepts/hbase_data_consistent/","categories":[["hadoop","/categories/hadoop/"],["hbase","/categories/hadoop/hbase/"],["hbase_basic_concepts","/categories/hadoop/hbase/hbase-basic-concepts/"]],"content":"HBCK - HBCK检查什么？1、HBase Region一致性集群中所有region都被assign，而且deploy到唯一一台RegionServer上该region的状态在内存中、hbase:meta表中以及zookeeper这三个地方需要保持一致2、HBase 表完整性对于集群中任意一张表，每个rowkey都仅能存在于一个region区间"},{"title":"HBase Shell","date":"2023-10-22T14:23:09.838Z","url":"/2023/10/22/hadoop/hbase/basic_concepts/hbase_shell/","categories":[["hadoop","/categories/hadoop/"],["hbase","/categories/hadoop/hbase/"],["hbase_basic_concepts","/categories/hadoop/hbase/hbase-basic-concepts/"]],"content":"1.登录 shell 2.列出所有的表 3.统计一个表中数据的行数【速度很慢，建议用 RowCounter】 4.清空｜删除表数据 5.查看一张表的前 N 条记录 6.查看一张表中指定 rowkey 的数据 7.Scan 扫描全表并指定返回特定的列 Scan 更多用法 8.写入原生的数据类型 9.HBaseFsck（hbck）HBaseFsck（hbck）是一个用于检查区域一致性和表完整性问题并修复损坏的HBase的工具。 10.重分配 region，解决 RIT 问题 11.查看表信息 12.RowCounter 统计 HBase 表行数 13.检查表状态 14.查看分区信息 15.找出异常的 Region 16.确认一下表的信息和数据 17.更新 Region&#x2F;Table 信息 18.查看多个版本的数据 2.19. 权限管理"},{"title":"HBase Meta Table","date":"2023-10-22T14:21:29.325Z","url":"/2023/10/22/hadoop/hbase/basic_concepts/hbase_meta_table/","categories":[["hadoop","/categories/hadoop/"],["hbase","/categories/hadoop/hbase/"],["hbase_basic_concepts","/categories/hadoop/hbase/hbase-basic-concepts/"]],"content":"1.hbase:meta 表hbase 删除会删掉 hbase:meta 中的信息吗? Master初始化完成的必要条件是，hbase:meta和hbase:namespace已经被分配完成并且可以读取。重启后，Regionserver上的Region不是由RS自己加载，而是等待Master读取Meta信息结合RIT信息进行分配。 hbase:meta 表中数据全部删除后重启集群，只有 hbase:namespace 的信息会重新生成并插入到 hbase:meta 表中，而其他所有用户表（用户自己创建的表）是不会恢复的。 如何恢复用户数据记录，参考如下"},{"title":"HBase Region Split","date":"2023-10-22T14:18:22.899Z","url":"/2023/10/22/hadoop/hbase/basic_concepts/hbase_region_split/","categories":[["hadoop","/categories/hadoop/"],["hbase","/categories/hadoop/hbase/"],["hbase_basic_concepts","/categories/hadoop/hbase/hbase-basic-concepts/"]],"content":"1.HBase Region 分裂。当Hbase运行时候，region达到了设置的文件大小后，就要开始分裂了。分裂的过程是：老region开始下线，is not online；老region分裂；老region关闭，is closing。"},{"title":"Java Data Type","date":"2023-10-22T14:14:03.026Z","url":"/2023/10/22/java/basic_concepts/java_data_type/","categories":[["java","/categories/java/"],["java_basic_concepts","/categories/java/java-basic-concepts/"]]},{"title":"TCP/UDP Socket Http WebSocket","date":"2023-10-22T10:45:11.110Z","url":"/2023/10/22/basic_concepts/tcp&socket&http&websocket/","categories":[["basic_concepts","/categories/basic-concepts/"]],"content":"1.轮询 长轮询 长连接2.TCP&#x2F;IP协议 三次握手 3.SocketSocket 不属于协议范畴，而是调用接口（API），是对 TCP&#x2F;IP 协议的封装，实现服务器和客户端间的物理连接。 4.Http协议 应用层协议 基于 TCP&#x2F;IP 协议 定义的是传输数据的内容规范 短连接 基于请求-响应形式 5.WebSocket"},{"title":"Terms","date":"2023-10-15T13:55:19.190Z","url":"/2023/10/15/terms/","categories":[[" ",""]],"content":"幂等性网卡亲和性"},{"title":"HBase Write/Read Performance Optimization","date":"2023-08-12T03:13:54.982Z","url":"/2023/08/12/hadoop/hbase/hbase_perf_optimization/","categories":[["hadoop","/categories/hadoop/"],["hbase","/categories/hadoop/hbase/"],["hbase_advanced","/categories/hadoop/hbase/hbase-advanced/"]],"content":"1.HBase 配置文件参数含义1.1.regionserver.handler.countregionserver.handler.count 是指单个 regionserver 允许的 rpc 请求的线程数量，默认值是 30，生产环境建议使用 60，也不是越大越好，特别是当请求内容很大的时候，比如 scan&#x2F;put 几 M 的数据，会占用过多的内存，有可能导致频繁的 GC（垃圾回收），甚至出现内存溢出。 1.2.hbase.hregion.memstore.block.multiplierhbase.hregion.memstore.block.multiplier 4&#x3D;&gt;5 1.3.hbase.hregion.memstore.flush.sizehbase.hregion.memstore.flush.size 134217728&#x3D;&gt;268435456 1.4.hbase.hstore.compaction.maxhbase.hstore.compaction.max 10&#x3D;&gt;15 1.5.hbase.regionserver.global.memstore.size调整 RegionServer 的读和写缓冲区的大小，此处 0.4 为 40%，读写缓存的总和控制在 80% 以内，否则可能造成 Hbase 无法启动的情况。根据写需求，可加大 hbase.regionserver.global.memstore.size 的比例默认读写缓存比例值都为40%如果为了提高写速度，可以将读调整为 10%，写调整为 70%。 2.读写性能调优2.1.避免 regionserver 级别的刷写regionserver 运行在 JVM 之上，regionserver 占用的堆内存是向 JVM 堆内存申请的。 hbase_heapsize（region server heapsize）是 RegionServer 占用的 JVM 内存大小。 hbase.regionserver.global.memstore.size 是一个 regionserver 总的写缓存（即所有 memstore 之和）占用 hbase_heapsize 的比例。【默认值是 0.4】 当一个 regionserver 总的写缓存（即所有 memstore 之和）&gt; hbase_heapsize ✖️ hbase.regionserver.global.memstore.size，就会触发 regionserver 级别刷写，阻塞 regionserver 的所有写请求，且时间较长。 2.2.设置合理的 region 数量和 region 大小bulkload 和 put 加载数据？ Jetty IOException: Too many open files client-scan 过滤数据：合理的region数量和region大小 HBase客户端设置缓存，批量提交，但是可能会因客户端崩溃损失数据。 HBase RegionServer可能会因为并发的请求太多陷入 TooBusyException 状态。 2.3.focus on CPU 绑核网卡亲和性 2.4.JVM GC 较多，如何减少 GC？通过 Java 进程监控，发现 GC 的问题。添加了内存，但是发现没有效果。 2.5.try changing the configurations of hbase clusters. 内存分页详解关闭透明大页 时钟同步问题导致 HBase 的多 Region Server 实例启不来。 2.6.20230531 3new servers which settings are alligned with x86三台服务器均摊一下SATA盘，每台机器都是13块硬盘插网线登录IBMS管理界面装openeuler系统接显示器、键盘鼠标，操作进行 BIOS 设置做 RAID 操作分配IP登录主机，修改主机名 hostnamectl主机名IP映射缓存可信认证，不用每次输密码时钟同步设置自己的YUM源（打包在了IOS镜像中），可供安装集群把 ambari HDP 等要用到的包放在 httpd 的 &#x2F;var&#x2F;www&#x2F;html 路径下供 HTTP 访问配置 ambari 的 yum 源，安装 ambari安装 MariaDB导入建表语句启动 ambari，访问 Web UI，安装 HDP配置 HDFS 的 namenode 和 datanode 的存储路径时，发现硬盘还没格式化用 linux 命令格式化硬盘mount 命令挂载硬盘 2.7.20230602terms collected单核能力、内存通道、916芯片内存页内存频率 内存带宽磁盘转速、带宽、单通道ARM单核的比不过X86，试图调度更多的核X86机器的内存页是4K 鲲鹏是64K？透明大页 TLB鲲鹏的 TLB 的 Miss很大内存的布局也是有讲究的，会影响内存速率带R和不带R的英特尔芯片intel的有超频，虽然40核但是80线程，arm的虽然60核但是没超频就是60线程X86是4K内存页大小，ARM的是64MB的内存页大小。 系统盘&#x2F;硬盘，格式化硬盘，系统盘不格式化软件的配置文件在系统盘中吗？格式化硬盘并不影响配置文件 rm 并不删的彻底，要进一步格式化？ numactl 绑核不绑核，会产生 CPU 跨内存调用的损耗。强制绑核，会使得 CPU 核心与相近的内存绑定。但是一旦绑定，会使得 CPU 核的内存变得有限，从而可能会使用交换空间 Swap。 交换空间关闭与否 内置的管理网页，例如华为服务器的IBMS、路由器的设置界面 CPU、磁盘IO、网卡 将Compaction下推到存储层(HDFS)执行，这样，每一个DateNode在本地合并自己的文件，这样可以降低一半以上的网络IO请求，但本地磁盘IO请求会增大，这事实上是用磁盘IO资源来换取昂贵的网络IO资源。在我们自己的测试中，我们也发现，将Compaction下推到HDFS侧执行，能够明显的优化读写时延毛刺问题。"},{"title":"Hive 手册","date":"2023-07-16T14:50:43.566Z","url":"/2023/07/16/hadoop/hive/","categories":[["hadoop","/categories/hadoop/"]],"content":"Hive 是一个分布式数据仓库系统 进入 Hive 命令行 查询当前用户 查看表分区信息"},{"title":"PebblesDB-Building key-value stores using fragmented log-structured merge trees","date":"2023-06-29T04:11:35.099Z","url":"/2023/06/29/academic_research/papers_read/PebblesDB-Building%20key-value%20stores%20using%20fragmented%20log-structured%20merge%20trees/","categories":[["academic_research","/categories/academic-research/"],["papers_read","/categories/academic-research/papers-read/"]],"content":"1. 文章基本信息1.1. 发表年份2017 1.2. 所在会议简称CCF A类 1.3. 文章作者列表1.4. 第一作者单位2. 论文阅读报告2.1. 论文研究背景 &amp; Motivation2.2. 解决的问题2.3. 主要创新点2.4. 实验效果"},{"title":"Building an Efficient Put-Intensive Key-Value Store with Skip-Tree","date":"2023-06-29T04:11:15.802Z","url":"/2023/06/29/academic_research/papers_read/Building%20an%20Efficient%20Put-Intensive%20Key-Value%20Store%20with%20Skip-Tree/","categories":[["academic_research","/categories/academic-research/"],["papers_read","/categories/academic-research/papers-read/"]],"content":"1. 文章基本信息1.1. 发表年份2016 1.2. 所在会议简称CCF A类 1.3. 文章作者列表1.4. 第一作者单位2. 论文阅读报告2.1. 论文研究背景 &amp; Motivation2.2. 解决的问题2.3. 主要创新点2.4. 实验效果"},{"title":"A Comparative Study of Secondary Indexing Techniques in LSM-based NoSQL Databases","date":"2023-06-27T13:10:43.650Z","url":"/2023/06/27/academic_research/papers_read/A%20Comparative%20Study%20of%20Secondary%20Indexing%20Techniques%20in%20LSM-based%20NoSQL%20Databases/","tags":[["LSM-tree","/tags/LSM-tree/"],["综述","/tags/%E7%BB%BC%E8%BF%B0/"]],"categories":[["academic_research","/categories/academic-research/"],["papers_read","/categories/academic-research/papers-read/"]],"content":"1. 文章基本信息1.1. 发表年份2018 1.2. 所在会议简称SIGMOD 1.3. 文章作者列表MohiuddinAbdulQader 1.5. 第一作者单位加州大学河滨分校计算机科学与工程系 2. 论文阅读报告2.1. 论文研究背景 &amp; Motivation2.1.1. BackgroundNoSQL 数据库由于其能快速写和基于主键快速查，因而在大数据应用中广泛被使用。但在实际应用中很多时候需要对非主键属性进行查询，因此也有多个 NoSQL 数据库已经支持二级索引了。但是这些工作都太碎片化，各个系统通常只支持一种二级索引，而且都有各自的叫法或者干脆没有名称。对于这些二级索引的吞吐率和空间占用，目前还没有实验对比或者性能分析。 2.1.2. 相关工作Yahoo PNUTS已经有了将二级索引组织为一张表的想法了； Cassandra通过填充一个单独的表（Cassandra术语中的列族）来存储每个索引属性的二级索引，从而支持二级索引。他们的索引更新遵从我们的懒惰索引方法。 AsterixDB引入了一个框架，用于将就地更新索引（如 B+ 树和 R-tree）转换为 LSM 风格的索引，以便高效地处理高吞吐量工作负载。他们的二级索引紧跟我们的 Composited Index 策略。这可以被视为对我们工作的补充，因为我们直接处理 LSM 友好的索引（一组带有平面发布列表的键）。AsterixDB 还采用 Zone Map 来清理磁盘组件（即 SSTables），以便进行二次查找。但是它们的区域映射是有限的，因为它们只是整个 SSTable 文件的最小-最大范围过滤器，而我们的区域映射还维护了 SSTable 内所有块的过滤器。 HBase 面向文档的 NoSQL 数据库，如 CouchDB 和 MongoDB类似于 RDBMs，采用 B+ 树来支持二级索引。它们大多对二级索引执行就地 In-place更新，类似于我们的 Eager 索引。 DualDB HyperDex Innesto DynamoDB Riak 2.1.3. Motivation对于各个NoSQL数据库的二级索引的吞吐率和空间占用，目前还没有实验对比或者性能分析。 2.2. 解决的问题对于当前流行的NoSQL数据库所采用的二级索引进行集中评测，对其吞吐率和空间占用进行实验对比和性能分析。方便实际应用中根据实际业务需求选择特定方案。 2.3. 主要创新点首先将 NoSql 二级索引分类，宽泛地分为两类 嵌入式索引即嵌入主表中的轻量级过滤器，包括布隆过滤和 Zone Maps。两者都是随着 SSTable 创建而顺序写入的，和 SSTable 一样都无需更新。 独立索引即独立的数据结构。根据更新方式又可分为：Eager Update Index、Lazy Update Index 和 Composited Index。 为了保证测试的公平，基于 Google 的 LevelDB 键值库构建了一个系统 LevelDB++，在该系统中实现了两种嵌入索引和三种最先进的独立索引，这些索引基本覆盖了流行的NoSQL 数据库。结果发现，并没有索引能够占据绝对的优势。具体来说，嵌入索引写效率更高且节省存储空间，然而独立索引的查询响应速率更高，在实际应用中需要根据具体业务场景挑选最优搭配。 实现两种嵌入索引额外追加二级属性的布隆过滤数据和 Zone Maps 数据。 实现两种带有 Posting Lists 的独立索引独立索引比嵌入索引的查询性能更强，因为它只读一次 Eager Index 或者至多读 L 次 Lazy Index（Lazy Index 有 L 层）就能得到所有的候选主键。但是当进行数据表的更新 PUT（K,V）和删除 DEL（K）操作时，索引表的维护就很耗时，因为要维持数据表和索引表的一致性。本论文实现了如下两种更新方式：Eager Update 和 Lazy Update。 实现带有 Composited Key 的独立索引索引表中数据存储形式为 &lt;(u1+t1), null&gt;。点查询或范围查询时都借助前缀匹配，得到候选，然后再校验是否合法。 2.4. 实验效果选择 LevelDB 是因为它是一个单线程纯单节点键值存储，因此我们可以很容易地分离和解释各种索引方法的性能差异。"},{"title":"HiKV: A Hybrid Index Key-Value Store for DRAM-NVM Memory Systems","date":"2023-06-27T13:02:37.872Z","url":"/2023/06/27/academic_research/papers_read/HiKV-A%20Hybrid%20Index%20Key-Value%20Store%20for%20DRAM-NVM%20Memory%20Systems/","categories":[["academic_research","/categories/academic-research/"],["papers_read","/categories/academic-research/papers-read/"]],"content":"1. 文章基本信息1.1. 发表年份2017 1.2. 所在会议简称USENIX ATC【CCF A类】 1.3. 文章作者列表Fei XiaDejun JiangJin XiongNinghui Sun 1.4. 第一作者单位SKL Computer Architecture, ICT, CASUniversity of Chinese Academy of Sciences 2. 论文阅读报告2.1. 论文研究背景 &amp; MotivationNVMNVM 技术能够提供比传统硬盘和 Flash 更快的持久化能力。NVM 提供和 DRAM 相似的读延迟，然而写延迟却明显比 DRAM 高。同时，和 NAND Flash 类似，NVM 的写入耐久度是有限的，尤其是 PCM。因此减少 NVM 写入对于软件系统设计来说很重要。 KV 操作和索引效率Put、Delete、Update、Get 是键值存储的基本操作，同时 Scan 操作也是如今键值存储的一个重要操作。支持高效率的密集 KV 操作对于构建键值存储很重要。然而哈希索引或排序索引都很难有效支持这些 KV 操作，使用 micro-benchmarks 基准测试方法测试了三种广泛使用在内存中的索引，让它们进行以上五种 KV 操作，三种索引包括：hash、skiplist 和 B+ 树。结果显示对于 Put、Delete、Update、Get 操作，hash 索引都表现的最好，和 skiplist 和 B+ 树相比，hash 涉及更少的内存操作，skiplist 和 B+ 树都需要多级搜索。但是作为无序索引，由于扫描整个索引空间的成本，对于 Scan 操作，哈希索引提供了极低的吞吐量。 Motivation当前的基于 NVM 的键值存储同样采用广泛使用的 B+ 树索引结构，但是以上测试结果激励我们提出一种混合索引结构去综合利用不同索引的优势。 2.2. 解决的问题充分利用不同内存介质和不同索引的优点，减少资源优势流失，提升密集KV操作的效率。 2.3. 主要创新点写入操作（Put&#x2F;Update&#x2F;Delete）不同于 Get 操作，他们需要保留更新的索引条目和新的 KV 项（如果提供），因而需要高效的索引检索和数据持久化能力。提出一种混合索引，Hash 索引放在 NVM 中，B+ 树索引放在 DRAM 中，充分利用混合内存结构的性能特征，高效支持密集 KV 操作。 Hash 与身俱来就支持高效率检索，同时 NVM 的读效率堪比 DRAM，于是将 Hash 索引放在 NVM 中就很合理。不仅保留了哈希索引的快速搜索，还允许直接在 NVM 中持久化索引，而无需将额外的数据从 DRAM 复制到 NVM。 B+ 树索引（有序）是为了支持 Scan 操作，因为更新 B+ 树需要维持有序，涉及很多的写操作（合并、分裂叶子节点），因而将其放在 DRAM 中，NVM 的写延迟相比 DRAM 较大。B+ 树索引被设计为全局索引，检索所有的 KV 对象。 采用有序写以确保 Hash 索引和 KV 对象的一致性。 2.4. 实验效果个人认为没有测评存储海量数据（几十 TB）的场景。没有确定 NVM 和 DRAM 能支持管理多大体积、多少数量的 KV 数据？"},{"title":"Bigtable: A Distributed Storage System for Structured Data","date":"2023-06-27T12:48:49.583Z","url":"/2023/06/27/academic_research/papers_read/Bigtable-A%20Distributed%20Storage%20System%20for%20Structured%20Data/","categories":[["academic_research","/categories/academic-research/"],["papers_read","/categories/academic-research/papers-read/"]],"content":"1. 文章基本信息1.1. 发表年份2006 1.2. 所在会议简称OSDI 1.3. 文章作者列表Fay Chang, Jeffrey Dean 1.4. 第一作者单位Google 2. 论文阅读报告2.1. 论文研究背景 &amp; Motivation为了满足来自不同Google产品的不同需求，提供一个灵活的、高性能的解决方案。 2.2. 解决的问题管理Google应用产生的跨越成千上万台商品服务器的PB级结构化数据。同时应对来自不同Google应用的各种各样的需求，例如数据大小（从URL到Web页面再到卫星图像数据）、延迟需求（从后端批量处理到实时数据服务）等。 2.3. 主要创新点2、数据模型简单的数据模型&lt;row:string, column:string, time:int64&gt;-&gt;stringRows在单个行键下，对数据的每次读取或写入都是原子性的。这使得在并发更新同一行数据的情况下，客户端很容易推断系统的行为。Bigtable按照rowkey的字典顺序来存储数据。一张table所对应的行范围是被动态地分区成多个子范围。每个子范围称为tablet，它是进行分配和负载均衡的单元。因此，读取较小行范围是高效的，它只需和一小部分的机器进行通信。客户端可以通过选择他们的rowkeys来利用这个属性，以便获得良好的数据访问局部性。例如可以调转域名字符串rowkey，这样同一个域名下的页面数据就可以存储在一起了。Column Families列键被分组为多个集合，这些集合称为列族，列族是访问控制的基本单元。一个列键用如下语法命名，family:qualifier。列族的名字必须是可打印的，但是限定符可以是任意的字符串。访问控制和内存磁盘记账都是在列族级别执行的。在数据能够被存储在一个列族中任意列键下之前，那个列族必须先被创建。TimestampsBigtable中的每一个cell可以包含相同数据的多个版本，这些版本可以通过时间戳来索引。Bigtable的时间戳是64 bit位的整数。时间戳可以由Bigtable分配也可以由客户端自己分配。一个cell的不同版本数据按照时间戳递减次序存储，为了最新版本的数据可以先被读取。我们可以设置Bigtable自动垃圾回收cell的版本数据，例如可以设置只保留最新的版本数据，或者只保留最近n个版本的数据。 4、Building BlocksBigtable建立在其它几个谷歌的基础设施之上。Bigtable使用分布式GFS来存储日志和数据文件。Bigtable 集群通常在运行各种其他分布式应用程序的共享机器池中运行，并且 Bigtable 进程通常与来自其他应用程序的进程共享相同的机器。Bigtable 依赖集群管理系统来调度作业、管理共享机器上的资源、处理机器故障和监控机器状态。Bigtable内部使用谷歌文件格式SSTable来存储数据。SSTable提供了一个持久的、有序的、从键到值的不可变映射，其中键和值都是任意的字节字符串。每个 SSTable 内部包含一系列blocks，通常每个block的大小为 64KB，但这是可配置的。存储在SSTable末尾的块索引被用来定位块，当SSTable被打开的时候，块索引就被加载进内存中。我们可以通过一次磁盘搜索来执行查找：首先通过在内存中的块索引上执行二分搜索找到合适的块位置，然后从磁盘读取该块数据。可选地，一个SSTable 可以完全映射到内存中，这允许我们在不接触磁盘的情况下执行查找和扫描。Bigtable 依赖于一个名为 Chubby 的高可用、持久的分布式锁服务。一个 Chubby 锁服务由五个活跃的副本组成，其中一个被选为 master 并主动服务请求。当大多数副本正在运行并且可以相互通信时，该锁服务是实时的。面对故障时，Chubby使用Paxos算法来保持副本的一致性。Chubby 提供了一个由目录和小文件组成的命名空间。每个目录或文件都可以用作锁，对文件的读写是原子的。 Chubby 客户端库提供了对 Chubby 文件的一致缓存。每个 Chubby 客户端维护一个与 Chubby 服务的会话。如果客户端无法在租约到期时间内续订其会话租约，则该客户端的会话到期。当客户端的会话过期时，它会丢失所有锁和打开的句柄。 Chubby 客户端还可以在 Chubby 文件和目录上注册回调，以通知更改或会话到期。Bigtable 使用 Chubby 来完成各种任务：（1）确保任何时候最多只有一个活跃的 master；（2）存储 Bigtable 数据的引导程序位置；（3）发现tablet服务器并最终确定tablet服务器死亡；（4）存储Bigtable的schema信息（每张table的列族信息）；（5）存储访问控制列表。如果 Chubby 长时间不可用，Bigtable 将不可用。 实现Bigtable 实现包含三个主要组件：一个链接到每个客户端的库、一个主服务器（master）和许多 tablet 服务器。Tablet服务器可以动态地添加或移除以适应工作量的变化。master服务器负责将tablet分配给tablet服务器、检测tablet服务器的添加和过期、平衡tablet服务器的负载、以及GFS中文件的垃圾回收。此外，它还处理schema更改，例如表和列族的创建。每个tablet服务器管理一组tablet（通常每个tablet服务器有十到一千个tablets）。 tablet服务器处理对它加载的 tablet 的读写请求，并且拆分已经变得太大的tablet。与许多单主机分布式存储系统一样，客户端数据并不经过master服务器：Bigtable客户端直接与tablet服务器通信进行读和写。因为客户端不依赖master服务器获取tablet位置信息，所以大多数客户端从不与master服务器通信。因此，master在实践中负载很轻。一个Bigtable集群存储了大量的table。每一个table又是由一系列的tablet组成的，每一个tablet又包含了与一个row range相关联的所有数据。刚开始的时候，每一个table只包含一个tablet，随着体积的增长，tablet自动分裂成多个子tablet，每一个子tablet默认大小为100-200 MB。 Tablet位置我们使用类似于 B+ 树的三级层次结构来存储tablet位置信息。第一级是一个存储在Chubby中的文件，该文件包含了root tablet的位置信息。这个root tablet包含了一个特殊的METADATA table中所有tablets的位置信息。每一个METADATA tablet又包含了一组user tablets的位置信息。其实，root tablet只是METADATA table中的第一个tablet，但它是被特殊对待的，即它绝不会被分割，是为了确保tablet位置层次结构不超过三层。METADATA table将一个tablet的位置存储在一个rowkey下，这个rowkey是这个tablet的表标识符及其结束行的编码。每个 METADATA Table行在内存中存储大约 1KB 的数据。以128 MB METADATA tablets的适度限制，该三级定位方案足以定位2^34 个tablets，128MB&#x3D;2^17KB，所以有2^17个METADATA行，每个METADATA Table行又索引一个User Tablet，同样每个User Tablet有2^17个行，每个User Table行又索引一个Tablet，所以一共可以定位〖2^17*2^17&#x3D;2〗^34 个tablets。也可称为用128 MB的tablets管理2^61字节数据，这是因为每个tablet默认大小在100-200MB，大概也就是2^20-2^28字节，所以2^34 个tablets大概就是2^61字节数据。客户端库会缓存tablet位置信息。如果客户端不知道某个tablet 的位置，或者它发现缓存的位置信息不正确，那么客户端库会递归地向上移动 tablet 位置层次结构。如果客户端的缓存为空，定位算法需要三次网络往返，包括一次从Chubby读取。如果客户端的缓存是陈旧的，定位算法可能需要多达6次往返，因为陈旧的缓存条目只有在未命中时才会被发现（假设 METADATA tablets 不经常移动）。虽然 tablet 位置信息存储在内存中，因此不需要 GFS 访问，但在常见情况下，我们通过让客户端库预取 tablet 位置信息进一步降低成本：每当读取 METADATA 表时，它都会读取多个 tablet 的元数据。我们还将辅助信息存储在 METADATA 表中，包括与每个tablet有关的所有事件的日志（例如服务器何时开始为其提供服务）。此信息有助于调试和性能分析。 Tablet分配每个tablet一次分配给一个tablet服务器。 master跟踪实时的tablet 服务器集合，以及tablets到tablet服务器的当前分配情况，包括哪些tablets尚未分配。当某个tablet 未被分配，并且某个tablet 服务器有足够空间容纳该tablet且可用时，master通过向tablet服务器发送tablet加载请求来分配tablet。Bigtable使用Chubby来跟踪tablet servers。当某个tablet server 启动时，它会在特定的Chubby目录（servers目录）中创建一个唯一命名的文件，并获得独占锁。master监控这个目录来发现tablet servers。一个tablet服务器如果失去了它的独占锁，那么它将停止服务它的tablets，例如由于网络分区导致tablet服务器丢失其 Chubby 会话。Chubby 提供了一种有效的机制，允许 tablet 服务器在不产生网络流量的情况下检查它是否仍然持有它的锁。只要文件仍然存在，tablet 服务器就会尝试重新获取其文件的独占锁。如果该文件不再存在，那么 tablet 服务器将永远无法再次提供服务，因此它会自行终止。无论一个tablet服务器何时停止（例如因为集群管理系统正在从集群中移除 tablet server 的机器），它会试图释放它的锁，以便master更快地重新为它分配tablets。master负责检测tablet服务器何时不再为其tablets提供服务，并负责尽快重新分配这些tablets。为了检测tablet server何时不再为其tablets提供服务，master定期向每个tablet server询问其锁的状态。如果一个tablet server报告失去了它的锁，或者如果master在最后几次尝试中无法到达服务器，master会尝试获取这个服务器的文件的独占锁。如果master能够获取到这个锁，说明Chubby服务还在，并且该tablet服务器要么是死了要么是无法到达Chubby，所以为了确保该tablet server永不会再提供服务，master将删除其对应的Chubby文件。一旦该服务器Chubby文件被删除，master可以将之前分配给该tablet服务器的所有 tablet移动到未分配的tablets集合中。为了确保 Bigtable 集群不会受到master和Chubby之间网络问题的影响，如果master的 Chubby会话过期，master会杀死自己。但是，如上所述，master 故障并不会改变tablets到tablet服务器的分配。当一个master被集群管理系统启动时，它需要先发现当前的tablet分配情况，然后才能更改它们。master在启动时执行以下步骤。（1）master在Chubby 中获取唯一的master锁，可以防止并发master实例化。（2）master扫描Chubby中的servers目录以发现在线服务器。（3）master与每一台在线的tablet服务器通信以弄清楚哪些tablet已经分配给每个tablet服务器。（4）master扫描METADATA表去学习了解tablet的集合。每当此扫描遇到尚未分配的tablet，master就会将其添加到未分配的tablet集合中，这使得tablet符合tablet分配条件。一个复杂的问题是只有METADATA tablets先被分配了，METADATA表的扫描才能发生。因此，在开始扫描之前（步骤4)，如果在步骤3中未发现root tablet已被分配，那么master将会把root tablet添加到未分配tablets集合中。此添加可确保root tablet将被分配。因为root tablet中含有所有METADATA tablets的名字，master将会在扫描root tablet之后，知道所有关于METADATA tablets的信息。现有的tablets集合仅在创建或删除表时发生变化，两个现有的tablets被合并形成一个更大的tablet，或者现有的tablet被拆分分成两个较小的tablet。master能够跟踪这些变化，因为它启动了除最后一个以外的所有变化。tablet拆分被特殊处理，因为它们是由tablet服务器发起的。tablet服务器通过在METADATA table中记录新tablet信息来提交拆分操作。当拆分完成时，它会通知master。如果拆分通知丢失（因为tablet服务器或master死亡），当master请求tablet服务器加载现在已经分裂的 tablet时，master检测到新的tablet。tablet server将会通知 master拆分，因为它在 METADATA table中找到的tablet条目将仅指定master要求它加载的tablet的一部分。 Tablet服务Tablet的持久状态是存储在GFS中的，如图5所示。 所有的更新会被提交到一个commit日志中，该日志存储了所有的redo记录。在这些更新中，最新提交的更新存储在内存中称为 memtable的有序缓冲区中，而较早的更新存储在一系列 SSTable文件中。当要恢复一个tablet时，tablet服务器将会从METADATA表中读取它的元数据，元数据包含一个SSTable的列表和一组redo点。SSTable列表构成了一个tablet，而redo点则是指向可能包含 tablet 数据的任何commit日志的指针。tablet服务器将 SSTables 的索引读入内存，并通过应用自redo点以来已提交的所有更新来重建内存表。当一个写入操作到达 tablet 服务器时，服务器会检查其格式是否正确，以及发送方是否有权执行变更。授权是通过从 Chubby 文件中读取允许的作者列表来执行的（这几乎总是在 Chubby 客户端缓存中命中）。一个有效的变动被写入commit日志。Group commit用于提高大量小变动的吞吐量。写操作被提交后，其内容将插入到 memtable 中。当读操作到达 tablet 服务器时，它也是类似地检查格式正确和适当的授权。在 SSTable 序列和内存表的合并视图上执行有效的读取操作。由于 SSTables 和 memtable 是按词典顺序排序的数据结构，因此可以有效地形成合并视图。在拆分和合并 tablet 时，传入的读取和写入操作可以继续。 压缩随着写入操作的执行，memtable内存表的大小会增加。当它的大小到达一定的阈值时，它会被冻结，一个新的memtable会被创建，被冻结的memtable会转换成一个SSTable并且写入GFS。这个较小的压缩过程有两个目标：它减少了 tablet 服务器的内存使用，并且当此服务器死机时，能减少在恢复期间必须从commit日志中读取的数据量。在压缩发生时，传入的读取和写入操作可以继续执行。 2.4. 实验效果"},{"title":"RepKV: A Replicated Key-Value Store to Boost Multiple Indices for Key-Value Separation","date":"2023-06-27T11:54:42.788Z","url":"/2023/06/27/academic_research/papers_read/RepKV-A%20Replicated%20Key-Value%20Store%20to%20Boost%20Multiple%20Indices%20for%20Key-Value%20Separation/","categories":[["academic_research","/categories/academic-research/"],["papers_read","/categories/academic-research/papers-read/"]],"content":"1. 文章基本信息1.1. 发表年份2022 1.2. 所在会议简称ICCD【CCF B类】 1.3. 文章作者列表Chenlei TangJiguang WanZhihu TanGuokuan Li 1.4. 第一作者单位Wuhan National Laboratory for Optoelectronics, Huazhong University of Science and Technology, Wuhan, China 2. 论文阅读报告2.1. 论文研究背景 &amp; Motivation许多前人工作插入元组 &lt;skey,pkey&gt; 构建二级索引，这使得查询skeys时很低效，具体来说得先获取pkey，然后再通过pkey查询得到value，这也就是索引导航问题。KV分离对于改进基于LSM的 KV 存储中多个二级索引的查询是有效的（索引导航问题）。KV分离就是将值存储在value log中，主键索引中只存储key和value的地址。SinKV进一步地将二级索引中也存储的是key和value的地址。但是这种多索引共享value得方案会导致效率不佳：(1) 对二级索引的查询和对所有索引的range查询不能同时充分利用 SSD 设备的带宽。(2) put 操作更新二级索引效率低下。基于WAL的副本方案会给KV分离带来严重的写放大问题。根源在于value log的垃圾回收GC。 Motivation副本的主要意义在于拷贝数据，因而放宽数据组织是合理的。在KV复制方面，只要能保证每一个KV对都被存储，我们可以在不同的复制中重新组织KV顺序，以利用SSD带宽。 2.2. 解决的问题(1) KV分离的缺点，对二级索引的查询和对所有索引的range查询不能同时充分利用 SSD 设备的带宽 ；对于 KV 对 &lt;pkey,skey1,skey2&gt;，是按主键 pkey 顺序存储在 value log 中的，当进行范围查询时，对于主键来说，是顺序读的，但是对于 skey1 和 skey2 则是随机读。 (2) put 操作更新二级索引效率低下； 2.3. 主要创新点KV 分离，Value 顺序写入 Vlog 中，进入 LSM-tree 的 KV 对中的 V 只是 Value 的存储地址。这样一来，在 Compaction 的时候就只需要管理 Value 的地址，大大减少了 Compaction 的负载。 （1）主备复制方案，每个副本存储相同的KV键值对，但基于角色的GC策略重新组织KV对以充分利用 SSD 设备的带宽。（2）RepKV 提出了一种轻量级复制方案，以减少复制中同步的额外KV对）。（3）RepKV 使用并行解析策略来提升 put 操作。 2.4. 实验效果"},{"title":"SineKV: Decoupled Secondary Indexing for LSM-based Key-Value Stores","date":"2023-06-27T08:48:47.443Z","url":"/2023/06/27/academic_research/papers_read/SineKV-Decoupled%20Secondary%20Indexing%20for%20LSM-based%20Key-Value%20Stores/","categories":[["academic_research","/categories/academic-research/"],["papers_read","/categories/academic-research/papers-read/"]],"content":"1. 文章基本信息1.1. 发表年份2020 1.2. 所在会议简称ICDCS【CCF B类】 1.3. 文章作者列表Fei LiYouyou LuZhe YangJiwu Shu 1.4. 第一作者单位TsingHua University 2. 论文阅读报告2.1. 论文研究背景 &amp; Motivation2.1.1. 基于 LSM-tree 的键值存储：LevelDB 和 WiscKey LevelDBLevelDB 源自 BigTable。LevelDB 的两个主要问题就是读放大和写放大。读放大是因为需要多级检查，检索 1KB 的 KV 对可能要读取 336KB 的数据。写放大主要源自 Compaction 过程。 WiscKey受到压缩只需要对 Key 进行排序的简单启示的启发，WiscKey 提出基于 LSM-tree 键值存储的 KV 分离存储。相比于 LevelDB，WiscKey 在 Compaction 过程中无需迁移 value，同时内存中能存储更多的 KV 对。 2.1.2. 二级索引技术2.1.2.1. 二级索引构建基于 B+ 树的 MongoDB 采用的是 in-place 更新方法，但是 in-place 更新并不适用于基于 LSM-tree 的键值库。基于 LSM-tree 的键值库构建二级索引的方法，主要有以下三种方法，如下图所示。 Eager 插入方法引发一个 read-write 序列操作，例如当插入新记录 {p3, s1, m3}，得先 get 得到 {s1 -&gt; p1,p2}，然后添加 p3，并 put 新记录 {s1 -&gt; p1,p2,p3}。这个 Eager 策略广泛使用在基于 B+ 树索引的系统中（如 MongoDB），但是在基于 LSM-tree 的系统中并不高效。 Lazy 插入方法这个方法被很多基于 LSM-tree 的系统采用（例如 Cassandra，DualDB）。当插入新记录 {p3,s1,m3}，直接 put 新记录 {s1-&gt;p3}。这样的话会降低二级检索速率，因为需要检索很多级的索引，需要改变当前 LSM-tree 结构的检索过程。 上面两种方法被分类为 key-list 索引。 Composite Key 方法AsterixDB、Spanner 等采用。当插入新记录 {p3,s1,m3}，生成一个复合 key&#x3D;s1+p3，即 pkey 作为 skey 的后缀，并 put 新记录 {s1+p3-&gt;””}。这样一来，查询 skey 就变成了 skey 的前缀查询，可以通过使用 range 查询接口来实现。Composite Key 方法简单明了，易于在当前基于 LSM-tree 的 KV 存储中部署。SineKV 就是基于这种方法。 2.1.2.2. 二级索引维护 采用 Composite Key 方法的二级索引，面对更新操作 `{p1->s1,u1,m1}=>{p1->s3,u1,m1}` 时，如果只是简单地插入记录 `{s3+p1->\"\"}` 会有问题，即当检索二级索引旧属性 s1 时，会得到 p1，然后根据 p1 检索主键，会返回新记录 `{p1->s3,u1,m1}`。 可以采用的一个方法是 eager update。AsterixDB,MyRocks,Phoenix 在使用。如 Figure3(b) 所示，先删除二级索引中的旧记录 {s1+p1-&gt;””}，然后再插入新记录 {s3+p1-&gt;””}。但是仍然需要一次额外的点查询去获取旧记录 {p1 → s1, u1, m1}。 还可以采用的一个方法是 lazy update。直接插入记录 {s3+p1 -&gt; “”}，但是在检索 s1 的时候，对返回结果 {p1 -&gt; s3, u1, m1} 做校验，发现 s3 并不等于 s1，便会舍弃。但是这样就增加了查询负担，且需要额外结构支持只检索不返回值的查询的验证操作。 2.1.3. NVMe SSD 的 CMB 特性NVMe (Non-Volatile Memory Express) 是非易失性存储设备的规范，成为通过 PCIe 接口连接 SSD 的普遍选择。NVMe SSD提供高吞吐、低延迟和优越的随机访问性能。但直到最近，SPDK 和 Linux 内核才将 CMB 用于 NVMe P2P 副本和 p2pdma。主机可以通过MMIO访问CMB，能传统的阻塞IO更灵活也更快。简而言之，CMB 提供了一个字节可寻址、非易失性和低延迟的接口来访问 NVMe SSD。 Cost 存储设备 Latency 高 DRAM 0.1us PMem NVMe SSD 3D NAND SSD SAS SSD SATA SSD 低 HDD(机械硬盘) 100us 2.1.4 Motivation当前的 KV 存储都采用的是一种紧耦合二级索引设计，当查询二级索引 skey 得到所有的主键索引 pkeys 并要获取相应的 record value 时，会进行索引导航。LSM-tree 键值存储本就存在读放大问题，点查询获取 record value 时会加剧高负载。受启发于 Wisckey 的 KV 分离，设计在二级索引中也只存储 value 的地址。 2.2. 解决的问题目前键值存储采用的都是紧耦合二级索引设计，有索引导航的问题，同时 LSM-tree 键值库有读放大的问题，索引导航带来的点查询会进一步加剧高负载。为了解决这些问题，提升二级索引 skey 的检索性能，提出解耦合二级索引设计方案。 2.3. 主要创新点为了避免从主索引中获取记录，将记录和索引分开，主键和二级索引都直接指向值，从而消除索引导航。记录的值存储在 SVLog 中，SVLog 用日志结构的方式存储 record value，主键索引和二级索引都可以读 SVLog，但是只有主键索引可以写 SVLog。SVMap 是在内存里的。主键索引和二级索引存储的都是 record value 的地址。二级索引中只需要存储记录值的地址，而记录值的地址又只占据很少的字节，因而向二级索引中存储记录值地址的代价微乎其微。Vinfo&#x3D;{fid(8bytes):offset(8bytes):length(8bytes)} 2.3.2. 基于映射的惰性索引维护策略。该策略是用来处理二级索引的 updates 的。 基于 lazy update 策略的传统系统中，过时记录与其最新版本在二级索引中共存，因而在返回 record 给客户端之前需要做校验。这样以来，对于仅检索不返回 record 的查询，为了校验，仍然要检索主键访问 value 值。 基于 eager update 策略，旧记录的所有索引都会被删除，新索引会插入。SVMap 记录的是旧二级索引 Vinfo 到新的二级索引 Vinfo 的映射关系。在一次更新操作中，SineKV 只需要为那些没有变化的二级索引属性添加一条映射信息就可以了，例如更新操作 &#123;p1,s1,u1,m1&#125;-&gt;&#123;p1,s3,u1,m1&#125;，只需要向 SVMap 中添加&#123;v1-&gt;v3&#125;，如图 Figure8(b) 所示。 SVLog 的垃圾回收KV 分离存储需要对 value 文件进行垃圾回收，SineKV 在 SVMap 的帮助下决定哪些记录失效了。 2.3.3. 利用底层 NVMe SSD 的 CMB 特性保证崩溃一致性SSD 页大小相对较大（32KB或更大），块 I&#x2F;O 一般以 4KB 为单位。持久化小写会导致部分写问题，这会导致读-修改-写操作。为 SVLog 提出基于 CMB 的 WAL 机制。将 WAL 直接建设在 NVMe SSD 的 CMB 区域里，而不是普通的文件里。 2.4. 实验效果"},{"title":"The Log-Structured Merge-Tree (LSM-Tree)","date":"2023-06-27T08:45:56.848Z","url":"/2023/06/27/academic_research/papers_read/The%20Log-Structured%20Merge-Tree%20(LSM-Tree)/","categories":[["academic_research","/categories/academic-research/"],["papers_read","/categories/academic-research/papers-read/"]],"content":"1. 文章基本信息1.1. 发表年份【1996】 1.2. 所在会议 &#x2F; 刊物简称ACTA【Acta Informatica】【CCF C类期刊】 1.3. 文章作者列表Patrick O’NeilEdward ChengDieter GawlickElizabeth O’Neil 1.4. 第一作者单位Dept. of Math &amp; C.S, UMass&#x2F;Boston, Boston, MA 2. 论文阅读报告2.1. 论文研究背景 &amp; Motivation2.2. 解决的问题2.3. 主要创新点2.4. 实验效果"},{"title":"WiscKey-Separating Keys from Values in SSD-Conscious Storage","date":"2023-06-27T08:45:56.848Z","url":"/2023/06/27/academic_research/papers_read/WiscKey-Separating%20Keys%20from%20Values%20in%20SSD-Conscious%20Storage/","categories":[["academic_research","/categories/academic-research/"],["papers_read","/categories/academic-research/papers-read/"]],"content":"1. 文章基本信息1.1. 发表年份1.2. 所在会议简称1.3. 文章作者列表1.4. 第一作者单位2. 论文阅读报告2.1. 论文研究背景 &amp; Motivation2.2. 解决的问题2.3. 主要创新点KV分离，Value顺序写入Vlog中，进入LSM-Tree的KV对中的V只是Value的存储地址。这样一来，在Compaction的时候就只需要管理Value的地址，大大减少了Compaction的负载。 2.4. 实验效果"},{"title":"dCompaction: Speeding up Compaction of the LSM-Tree via Delayed Compaction","date":"2023-06-27T07:23:14.025Z","url":"/2023/06/27/academic_research/papers_read/dCompaction-Speeding%20up%20Compaction%20of%20the%20LSM-Tree%20via%20Delayed%20Compaction/","categories":[["academic_research","/categories/academic-research/"],["papers_read","/categories/academic-research/papers-read/"]],"content":"1. 文章基本信息1.1. 发表年份【2017】 1.2. 所在会议简称NPC【CCF B类】 1.3. 文章作者列表Feng-Feng PanYin-Liang YueJin Xiong 1.4. 第一作者单位State Key Laboratory of Computer Architecture, Institute of Computing Technology, Chinese Academy of SciencesUniversity of Chinese Academy of Sciences 2. 论文阅读报告2.1. 论文研究背景 &amp; Motivation典型的 KV 存储负载，已经从 2010 年 80%-90% 读到 2012 年只有 50% 读，在典型的低延迟负载中，和读相比，写比例不断增加。写操作更可能成为后端存储系统的性能瓶颈，因为整个系统中有多级缓存可以吸收读请求，例如 Web 浏览器的缓存、CDN、Redis、Memcached、OS page cache，而写只能写进持久化存储设备中以确保数据的持久性。Facebook 的图片缓存机制分析结果表明 90.1% 的读请求被多级缓存响应，只有 9.9% 的读请求需要后端存储服务来响应。因此，面向写优化的数据结构 LSM-tree 以及它的变体获得了很多关注，且已广泛使用在 KV 存储系统中，例如分布式 KV 存储 Bigtable,Cassandra,HBase,Pnuts等，本地 KV 存储例如 LevelDB,RocksDB。但当前的合并策略会引发极大的写放大，因为重复的 KV 数据读写。 如果 M &#x3D; (Size(Ci+1) &#x2F; Size(Ci))(Size() 意思是 component Ci 的大小)，为了将 component Ci 中的 B 字节数据推送到 component Ci+1，需要进行一次合并操作，合并操作包括 (M+1)×B 字节的读 I&#x2F;O 和 (M+1)×B 字节的写 I&#x2F;O。M 被称为放大系数，RocksDB 中 M 值默认是 10。 很明显，写放大非常影响 LSM-tree 的吞吐量。 如下，已经有一些工作研究如何提升基于 LSM-tree 的 KV 存储的写性能了。VT-treebLSMPEPCP然而所有的研究都集中在降低 compaction 频率、加快 compaction 速度或将 compaction 限制在热数据 key 范围内。 2.1.1. LSM-treeC0 层在内存 Memory 中，C1 层及更高层在 Disk 中。每一个 disk component 由多个 SSTable 组成，SSTable 的大小是固定的，记为 V，且除了第 C1 层，这些 SSTable 的 key 范围是没有重叠的。 2.1.2. Compaction Procedure and Write Amplification in LSM-Tree在 compaction 过程中，首先将 Ci 层和 Ci+1 层的处于同一 key 范围内的 KV 项读入内存，然后做合并排序，最后写回 Ci+1 层的固定大小的 SSTables 中。不幸的是，compaction 过程非常需要 I&#x2F;O。我们将写入放大比（WAR）定义为磁盘的实际写入量与用户写入的数据量之间的比例。 Ci+1 层中包含的与 Ci 层中的 SSTables 键重叠的 SSTables 的数量也接近 M。这意味着在 compaction 期间，将一个 SSTable 从 Ci 层移动到 Ci+1 层需要读取（M+1）× V 个字节，并将（M+1）× V 个字节写入磁盘。因此，我们可以说 WAR 是 11，即WAR=M+1。回想一下，对于在 compaction 过程中从 C0 层流向 Ck 的 KV 项，WAR 可高达 K ×（M+1）。 在 RocksDB 上进行 100% 写放大实验，结果如下图所示。 与此同时，不考虑 Scan 操作，基于 LSM-tree 的 KV 存储的磁盘 I&#x2F;O 包括：log I&#x2F;O, get I&#x2F;O and compaction I&#x2F;O. Log I&#x2F;O is the write-ahead log I&#x2F;O for ensuring the reliability of KV items. Get I&#x2F;O is issued to get the specific KV items from disk-resident SSTables. Compaction I&#x2F;O includes reading KV items from disk-resident SSTables and writing KV items that were sorted and merged to SSTables. 我们在 RocksDB 上进行实验，探究这三种 I&#x2F;O 的占比，结果如下图所示。在这个实验中，update 和 get 操作都被合并了，我们设置 get 操作的比例从 0% 到 90%，从实验结果图中可以看到，写放大消耗了主要的磁盘 I&#x2F;O 带宽。 2.1.3. Motivation如下图所示，传统的 compaction 过程存在重复的读和写。 2.2. 解决的问题避免重复的 KV 项读和写，从而减轻写放大。 2.3. 主要创新点2.3.1. Delayed Compaction提出减小写放大的 delayed compaction (dCompaction)方法，dCompaction 推迟一些 compaction，并将它们聚集到之后的 compaction 中。通过引入 Virtual SSTable 和 Virtual Compaction，减少 Compaction 频率，延迟 Compaction，当达到一定的阈值时，才会触发真正的 Compaction 操作。和 real compaction 相比，virtual compaction 有着更小的 compaction I&#x2F;O 负载，因为只有一个元数据生成阶段，而 real compaction 有数据生成和元数据生成两个阶段。可以视为 Tiering Merge Policy 的一种变体。Above image Figure.6 shows the basic process of dCompaction. T22, T32 and T33 are converted to VT34, VT35 and VT36 via virtual compaction and only metadata are recorded in VT34, VT35 and VT36; thus it skips compaction I&#x2F;O overheads resulted from real compaction, such as compaction shown in Fig.4. In the following real compaction, it merges T42, T43 with other SSTables which VT34, VT35 and VT36 are derived from, i.e., T22, T32 and T33, into T44, T45, T46, T47 and T48. Compared with conventional compaction scheme, T22, T32 and T33 are read and written only once in dCompaction; hence the repeated I&#x2F;O overheads can be reduced, and write amplification can be greatly reduced. 2.3.2. Trigger Condition: VCTVCT 作为参数来控制 Compaction 过程是采取 real compaction 还是 virtual compaction。VCT 为 0，dCompaction 退化为传统的 compaction，随着 VCT 增加，virtual compaction 增加，但是大量的 virtual compaction 带来的负面影响是： 堆积了大量的 virtual compaction，当触发 real compaction，那时的负载是巨大的，非常影响读写性能，也就是说，较大的VCT延长了随后的实际压缩，从而导致突发写入吞吐量； 非常影响读性能，因为增加了读的查询路径； 2.3.3. VSMTVSMT 参数的设置也要合理。 2.4. 实验效果基于 RocksDB 实现 dCompaction，并进行扩展性实验。使用 YCSB 工具进行验证，和 RocksDB 进行比较，结果发现写性能提升了 40%，读性能相当。"},{"title":"LSM-based Storage Techniques: A Survey","date":"2023-06-21T07:16:21.730Z","url":"/2023/06/21/academic_research/papers_read/LSM-based%20Storage%20Techniques-A%20Survey/","tags":[["LSM-tree","/tags/LSM-tree/"],["综述","/tags/%E7%BB%BC%E8%BF%B0/"]],"categories":[["academic_research","/categories/academic-research/"],["papers_read","/categories/academic-research/papers-read/"]],"content":"1. 文章基本信息1.1. 发表年份【2018】 1.2. 所在会议简称VLDB【CCF A类】 1.3. 文章作者列表Chen LuoMichael J. Carey 1.4. 第一作者单位University of California, Irvine 2. 论文阅读报告2.1. 论文研究背景 &amp; Motivation2.1.1. LSM-tree 的基础知识2.1.1.1. LSM-tree 的历史通常来说，一个 index structure 可以从以下两种策略中选择其一去处理更新，in-place updates 和 out-of-place updates。 in-place updates structure例如 B+ 树就是 in-place updates structure，直接重写旧记录以存储新记录。这些结构通常是读取优化的，因为只存储每个记录的最新版本。然而，这种设计牺牲了写入性能，因为更新会导致随机 I&#x2F;O。此外，Index Page 可能被更新和删除操作分割，从而降低空间利用率。 out-of-place updates structure例如 LSM-tree，这种设计提高了写入性能，因为它可以利用顺序 I&#x2F;O 来处理写入。它还可以通过不覆盖旧数据来简化恢复过程。然而，这种设计的主要问题是牺牲读取性能，因为记录可能存储在多个位置中的任何一个。此外，这些结构通常需要单独的数据重组过程来持续地提高存储和查询效率。 sequential, out-of-place updates 的想法并不新鲜，自 1970 年代以来，它已经成功地应用于数据库系统。1976 年提出的 Differential files 是 out-of-place updates 结构的早期例子。在此设计中，所有 updates 首先应用于 a differential file，后者周期性地和 main file 合并。 后来，在 1980 年代，Postgres 项目开创了 log-structured 数据库存储的思想，Postgres 将所有写入追加到一个顺序日志中，实现了快速恢复和 time-travel 查询，与此同时它使用一个名为 vacuum cleaner 的后台进程从日志中不断地 GC 过时的记录。文件系统社区也采用了类似的想法来充分利用磁盘写入带宽，例如 Log-Structured File System (LFS)。 在 LSM-tree 出现之前，log-structured 存储的方法存在几个关键问题。首先，将数据存储到 append-only 日志中会导致查询性能低下，因为相关记录分散在日志中。另一个问题是由于尚未删除的过时记录导致的低空间利用率。即使设计了各种 data reorganization 过程，也没有原则性的成本模型来分析 写入成本、读取成本和空间利用率 之间的权衡，这使得早期的 log-structured storage 难以调优， data reorganization 很容易成为性能瓶颈。 1996 年提出的 LSM-tree 通过设计 merge 过程来解决这些问题，merge 过程集成到 structure 自身中，提供了具有有限查询性能和空间利用率的高写入性能。如图所示，最初的 LSM-tree 包含了一系列的 components，如 C0, C1, ···, Ck，每个 component 的结构都是 B+ 树。C0 存储在内存中，用于服务接收到来的写请求，剩余的组件 component 存储在磁盘中。当Ci 已满时，将触发 rolling merge 过程，将 Ci 中的一系列 leaf pages 合并到 Ci+1 中。这种设计现在通常被称为 leveling merge 策略。然而，正如我们将在后面看到的，最初提出的 rolling merge 过程由于其实现的复杂性而不被今天的基于 LSM-tree 的存储系统所使用。关于 LSM-tree 的原始论文进一步表明，在稳定的工作负载下，当所有相邻 component 之间的大小比 Ti&#x3D;|Ci+1| &#x2F; |Ci| 相同时，写入性能得到优化。这一原则影响了 LSM-trees 的所有后续实现和改进。 与 LSM-tree 同时，Jagadish 等人提出了一种具有 stepped-merge 策略的类似结构，以实现更好的写入性能。它将这些 components 组织成多个 level，当 level L 充满 T 个 component 时，这 T 个 component 在 level L+1 合并成一个新 component 。这个策略成为了今天的 LSM-tree 实现中使用的 tiering merge 策略。 2.1.1.2. LSM-tree 的现状2.1.1.2.1. 基本结构今天的 LSM-tree 实现仍然采用的是 out-of-place 的更新方式，用以减少随机 I&#x2F;O。对于 insert 和 update 操作只是简单地插入一条新的项，对于 delete 操作，是添加一个 anti-matter entry 表明该 key 已经被删除了。 memory components using a concurrent data structure such as a skip-list or a B+-treeorganize their disk components using B+-trees or sorted-string tables (SSTables) 随着磁盘 components 随着时间的推移而积累，LSM-tee 的查询性能往往会下降，因为必须检查更多的 components。为了解决这个问题，磁盘 components 逐渐合并，以减少 components 的总数。在实践中，基于 LSM-tree 的 NoSQL 数据库通常使用如下两种类型的合并（Compaction &#x2F; Merge）策略，这两种策略都将磁盘 component 组织成逻辑 level（或 tiers），并由 a size ratio T 控制。Leveling 合并策略 每一 level 仅维护一个 component，但 level L 的 component 比 level L-1 的 component 大 T 倍。 每一 level L 的 component 将与 level L-1 到来的 components 合并 T-1 次，直到层满写入下一层。 每一 level 的 Key-Value 之间是没有重叠的。 读性能更好，因为只需要检索更少的 Components。 Tiering 合并策略 每一 level 至多维护 T 个 components。 每一 level 层满时，T 个 components 只合并一次，并直接写入下一层。 每一层 Key-Value 之间允许有重叠。 拥有更好的写性能，因为减少了合并频率。 如果 level L 已经是配置的最大 level，则生成的 component 保持在 level L。实践中，对于 insert 量等于 delete 量的稳定工作负载，level 的总数保持不变，即使对于以 append 为主的工作负载，level 的总数也会增长得非常缓慢，因为随着 level 数量的增加，LSM-tree 可以存储的最大条目数量以因子 T 呈指数级增长。 2.1.1.2.2. 著名的优化手段【已应用】 Bloom Filter提升点查询性能；可能假阳性，但不会假阴性。 Partitioning即将大 Disk Component 拆分为更小的分区 partition，我们用术语 SSTable 表示这么一个分区 partition。Partitioning 优点：1）Partitioning 将一个大的 component compaction 操作分成多个较小的 compaction 操作，限制了每个小 compaction 操作的处理时间以及创建新 component 所需的临时的磁盘空间。2）Partitioning 可以通过仅合并具有重叠键范围的 component 来优化具有顺序创建的键或倾斜更新的工作负载。对于顺序创建的键，基本上不执行合并，因为没有具有重叠键范围的组件。对于倾斜更新，具有冷更新范围的组件的合并频率可以大大降低。应该注意的是，原始的LSM树自动利用 Partitioning ，因为它有 rolling merge。然而，由于 rolling merge 的实现复杂性，今天的 LSM-tree 实现通常选择实际的物理分区，而不是 rolling merge。 注意 Partitioning 和 Merge Policy 是正交的，如下所示。 Leveling Merge Policy Tiering Merge Policy Partitioning RocksDB、LevelDB 2.1.1.2.3. Concurrency Control and Recovery2.1.1.3. LSM-tree 的 Cost AnalysisCost Analysis 包括写、读、空间利用率。 2.1.2. Motivation2.2. 解决的问题2.3. 主要创新点2.3.1. 介绍了一种对已提出的 LSM-tree 改进方法的分类法，并根据该分类法调研了现有的研究工作。 Write AmplificationTieringMerge SkippingExploiting Data Skew Merge OperationImproving Merge PerformanceMinimizing Write StallsReducing Buffer Cache Misses HardwareLarge MemoryMulti-CoreSSD &#x2F; NVMNative Storage Handling Special WorkloadsTemporal Data时空数据Small Data小体积数据Semi-Sorted Data半排序数据Append-mostly Data大部分追加数据 Auto-TuningParameter TuningTuning Merge PoliciesDynamic Bloom Filter Memory AllocationOptimizing Data Placement Secondary IndexingIndex StructureIndex MaintenanceStatistics CollectionDistributed Indexing 2.3.2. 重点调研一些代表性的基于 LSM-tree 的 NoSQL 系统的存储层。2.3.3. 总结调研结果，并为未来基于 LSM-tree 的存储系统的工作确定了几个 outages 和机会。2.4. 实验效果"},{"title":"MatrixKV: Reducing Write Stalls and Write Amplification in LSM-tree Based KV Stores with a Matrix Container in NVM","date":"2023-06-21T07:10:07.604Z","url":"/2023/06/21/academic_research/papers_read/MatrixKV-Reducing%20Write%20Stalls%20and%20Write%20Amplification%20in%20LSM-tree%20Based%20KV%20Stores%20with%20a%20Matrix%20Container%20in%20NVM/","categories":[["academic_research","/categories/academic-research/"],["papers_read","/categories/academic-research/papers-read/"]],"content":"1. 文章基本信息1.1. 发表年份2020 1.2. 所在会议简称USENIX ATC 1.3. 文章作者列表Ting YaoYiwen ZhangJiguang Wan1Qiu CuiLiu TangHong JiangChangsheng XieXubin He 1.4. 第一作者单位WNLO, Huazhong University of Science and Technology, ChinaKey Laboratory of Information Storage System, Ministry of Education of China 2. 论文阅读报告2.1. 研究背景 &amp; Motivation写放大的原因在于 LSM-Tree 的 Leveling 太多。写停顿的主要原因在于每一次 L0 到 L1 层的合并需要处理大量的数据。 2.1.1. NVM（Non-volatile Memory）NVM是字节可寻址的、持久化的、快速的。既可以作为PCIe接口访问的持久块存储设备，也可以作为通过内存总线访问的主内存。前者有点浪费NVM的高媒介性能，作为后者，NVM可以替代或者补充DRAM。基于SSD的RocksDB，L0到L1层的合并需要处理大量的数据，是因为L0是无序的，L0中的SSTable的Key范围又很广，所以L0到L1的合并涉及两个Level中几乎所有的SSTables，这就导致了大规模的all-to-all合并 2.1.2. LSM-tree（Log-structured Merge Tree）2.1.3. 基于 LSM-tree 的 KV 存储2.1.4. 挑战和 Motivation 挑战一：写停顿System performance experiences peaks and troughs, and the troughs of throughput manifest as write stalls系统性能会经历高峰和低谷，吞吐量的低谷表现为写停顿。The significant fluctuations indicate unpredictable and unstable performance大幅波动表明性能不可预测且不稳定。L0 层到 L1 层的 Compaction 操作是写停顿的主要原因，合并数据量平均为 3.1 GB。 挑战二：写放大WA(Write Amplification) causes performance degradation. System performance (i.e., the average throughput) shows a downward trend with the growth of the dataset size since the number of compactions increases with the depth of LSM-trees, bringing more WA.WA会导致性能下降。随着数据集大小的增长，系统性能（即平均吞吐量）显示出下降趋势，因为合并操作的数量随着 LSM 树的深度 而增加，从而带来更多的 WA。 NoveLSM加剧了写停顿 2.2. 解决的问题该论文同时关注：减小写放大、减轻写停顿。本论文主要解决 L0 层到 L1 层合并过程导致的写停顿问题。同时提出方案减小 LSM-Tree 的深度，从而减小写放大。 2.3.主要创新点本论文方案是构建多层存储 DRAM-NVM-SSD，主要研究点有以下四个。 Matrix Container无序的L0层存储在NVM中，由Matrix Container管理。 Column Compaction合并L0和L1时，使用更细粒度的列合并，减少合并数据量，从而减轻写停顿。 Reducing LSM-Tree Depth增加每一个Level的宽度，从而减小LSM-Tree的深度，从而减轻写放大。 Cross-row hint search 以下分别描述四个研究点内容。 2.3.1. Matrix ContainerL0 层存储在 NVM 中，并使用 Matrix Container 管理，L1 及以下层存储在 SSD 中。L0 层放置 NVM 中就变得可控了，可以人为定义合并策略，减小合并粒度。Matrix Container 组成 —— Receiver &amp; RowTable &amp; Compactor Receiver RowTable将 NVM page 作为基本存储单元，和传统的 SSTable 不同，后者基本存储单元是 Block。 Compactor用于从 L0 中选择和合并数据进 L1 中。 2.3.2. Column Compaction2.3.3. Reducing LSM-Tree Depth2.3.4. Cross-row hint search2.4. 实验效果3. 词汇elaborate 详细阐述overlapping key range 重叠的键范围"},{"title":"概览","date":"2023-06-09T13:38:44.660Z","url":"/2023/06/09/db_overview/","categories":[[" ",""]],"content":"数据库存储引擎处理更新采用两种方法： 原地更新（in-place updates） 异地更新（out-of-place updates）原地更新结构（比如B+树）是直接将新的数据覆盖到原有的位置，这样虽然会带来好的查询性能，但是这样做导致随机IO，会极大降低写性能，并且多次更新和删除会严重导致磁盘页面碎片化问题，从而降低了空间利用率。 相反，异地更新结构（比如LSM树）则是将更新数据存储在新的位置，而不是覆盖原有的旧数据。这样做利用了操作系统的顺序IO，从而提高了写性能，并且由于旧数据的存在，使得数据恢复变得很简单了。但是这样做牺牲了读性能，因为必须要读取所有位置的记录才能得到正确的数据。于是就需要一个将离散数据重新组织的方法将读和写性能达到一个平衡。"},{"title":"NoSQL Overview","date":"2023-06-09T11:33:50.260Z","url":"/2023/06/09/basic_concepts/nosql/","categories":[["basic_concepts","/categories/basic-concepts/"]],"content":"不是所有的 NoSQL 数据库都是键值数据库。虽然键值数据库是 NoSQL 数据库的一种常见类型，但还有其他类型，如面向文档、列族和图形数据库。 1.键值数据库在键值数据库中，数据存储为键值对的集合，其中每个值都与一个唯一的键相关联。键值数据库的例子包括： Redis Riak Amazon DynamoDB 2.面向文档的数据库面向文档的数据库将数据存储为文档，通常是JSON或XML格式。面向文档的数据库的例子包括： MongoDB Couchbase 3.列族数据库列族数据库将数据存储在列而不是行中，这可以为某些类型的查询提供更好的性能。列族数据库的例子包括： Apache Cassandra HBase 4.图数据库图形数据库以图形结构存储数据，这对于表示和查询数据点之间的复杂关系非常理想。图形数据库的例子包括： Neo4j OrientDB "},{"title":"Cent OS 7 上配置 SSSD for LDAP","date":"2023-06-07T13:10:34.526Z","url":"/2023/06/07/sssd%20for%20ldap(centos7)/","categories":[[" ",""]],"content":"1.简介SSSD，即System Security Services Daemon，系统安全服务守护进程，是最初为Linux操作系统开发的软件，它提供了一组守护程序来管理对远程目录服务和身份验证机制（例如LDAP、Kerberos等）的访问。SSSD目的在于简化系统管理涉及多个不同主机、已经过身份验证和授权的用户访问。它旨在为基于类 Unix 操作系统的网络提供单点登录功能，类似于 Microsoft Active Directory 域服务为Microsoft Windows 网络提供的功能。SSSD是介于本地用户和数据存储之间的进程，先由SSSD连接认证服务器取得认证和授权信息，再交于本地客户端程序。SSSD 提供 PAM 和 NSS 模块来将远程源集成到系统中，并允许远程用户登录并被识别为有效用户，包括组成员。使用SSSD的优势如下： 1.避免了本地每个客户端程序对认证服务器大量连接，所有本地程序仅联系SSSD，由SSSD连接认证服务器或SSSD缓存，有效的降低了负载。 2.允许离线授权。SSSD可以缓存远程服务器的用户认证身份，这允许在远程认证服务器宕机时，继续成功授权用户访问必要的资源。 2.配置OpenLDAP和SSSD首先安装SSSD包，执行如下安装命令 下一步需要配置OpenLDAP支持TLS服务，首先生产自签名证书，步骤如下。 自此得到CA证书、CA私钥、OpenLDAP的TLS证书和OpenLDAP的TLS私钥，可以将相关证书和文件复制到指定目录下供使用，示例如下。 接着编辑文件 &#x2F;etc&#x2F;sysconfig&#x2F;slapd，向参数SLAPD_URLS&#x3D;”ldapi:&#x2F;&#x2F;&#x2F; ldap:&#x2F;&#x2F;&#x2F;“添加ldaps:&#x2F;&#x2F;&#x2F;。备份Openldap的slapd.d目录下配置文件。 如果没有slapd.conf配置文件，需要创建并编辑其中配置项，可执行命令vi slapd.conf并添加如下内容，注意其中的TLS相关证书文件的路径设置，见上文路径信息，保存退出。注意&#x2F;etc&#x2F;openldap&#x2F;ldap.conf文件是LDAP服务器的客户端配置文件，由openldap_clients 生成，与slapd.conf区分开，此处并不需要配置ldap.conf文件。 每次修改完配置文件slapd.conf后，都需要先删除slapd.d文件目录下的内容， 然后再重启slapd服务。 至此OpenLDAP的TLS服务配置完成。下面添加用户供测试，首先创建user.ldif文件，添加如下内容。 再通过ldap客户端命令ldapadd添加该DN信息。其中可以先不设置userPassword字段信息，因为可以通过ldap客户端命令后期修改密码，命令如下。 下面接着配置SSSD服务。首先配置NSS和PAM，执行如下命令。 &#x2F;etc&#x2F;sssd&#x2F; 目录下若没有配置文件 sssd.conf需创建，在文件中添加并编辑如下配置项。 编辑好配置文件后，需要设置配置文件的权限。如果不设置的话，启动时会报错：“Cannot read config file &#x2F;etc&#x2F;sssd&#x2F;sssd.conf. Please check that the file is accessible only by the owner and owned by root.root”。执行命令如下。 设置完成后，启动SSSD服务systemctl start sssd，然后就可以通过如下命令验证是否配置成功了。 3.错误记录3.1.报错“Could not start TLS encryption. unsupported extended operation；Backend is offline”。将ldap:&#x2F;&#x2F; 改成ldaps:&#x2F;&#x2F;，同时需要配置OpenLDAP的TLS服务。OpenLDAP监听的端口：默认监听端口389（明文数据传输），加密监听端口636（密文数据传输，TLS服务的端口为636。 3.2.启动LDAP报错“_sasl_plugin_load failed on sasl_auxprop_plug_init for plugin:ldapdb，_sasl_plugin_load failed on sasl_canonuser_init for plugin: ldapdb，_sasl_plugin_load failed on sasl_auxprop_plug_init for plugin: sql”。执行如下命令：rpm -e cyrus-sasl-ldaprpm -e cyrus-sasl-sql 3.3.启动LDAP报错objectclass: AttributeType not found: “audio”inetOrgPerson depends on both core and cosine. It looks like you already have core. Add in cosine, then inetorgperson. Cosine should be at &#x2F;etc&#x2F;openldap&#x2F;schema&#x2F;cosine.ldif. 3.4.启动LDAP报错“TLS init def ctx failed: -1”重建certs文件夹mkdir -p &#x2F;etc&#x2F;openldap&#x2F;certs重新创建certs文件夹中的证书bash &#x2F;usr&#x2F;libexec&#x2F;openldap&#x2F;create-certdb.shbash &#x2F;usr&#x2F;libexec&#x2F;openldap&#x2F;generate-server-cert.sh 3.5.SSH登录报错“pam_ldap(sshd:auth): error opening connection to nslcd: No such file or directory”需要启动nslcd，执行命令service nslcd start。 3.6.LDAP添加用户报错“ldap_add: Invalid syntax (21) additional info: objectClass: value #1 invalid per syntax”objectClass: account is not avaible in file core.schema，You need to include both cosine.schema and nis.schema given the objectclasses you’re using. 3.7.Failed to parse ldap URI (ldaps:&#x2F;&#x2F;172.20.9.29:636 #hostname是 ldap服务器的ip地址或主机名。)!注释不要和配置项写在同一行，影响解析。 4.其它  删除SSSD缓存：配置字段含义：配置OpenLDAP 的TLS服务：配置SSSDforLDAP：配置 SSSD 以使用 LDAP 并需要 TLS 身份验证：直接与OpenLdap集成："},{"title":"硬件｜协议｜标准","date":"2023-06-07T12:24:13.265Z","url":"/2023/06/07/hardware/","categories":[[" ",""]],"content":"PCIe快速外围设备互连（PCIe或PCI-E）是一种串行扩展总线标准，用于将计算机连接到一个或多个外围设备。与PCI和PCI-X等并行总线相比，PCIe提供了更低的延迟和更高的数据传输速率 DMA (Direct memory access)直接内存访问是计算机科学中的一种内存访问技术。它允许某些电脑内部的硬件子系统，可以独立地直接读写系统内存，而不需中央处理器介入处理。在同等程度的处理器负担下，DMA是一种快速的数据传送方式。很多硬件的系统会使用DMA，包含硬盘控制器、绘图显卡、网卡和声卡。 SSD NVM NVMeSSD 是一种利用了 NVM 技术的设备。NVMe 是一种规范。NVMe SSD 比普通的 SSD 要更快。 持久内存 PMem SSD HMB 和 CMB 机械硬盘对于普通机械磁盘顺序写的性能要比随机写大很多。比如对于15000转的SAS盘，4K写IO， 顺序写在200MB&#x2F;s左右，而随机写性能可能只有1MB&#x2F;s左右。而LevelDB的设计思想正是利用了磁盘的这个特性。 LevelDB的数据是存储在磁盘上的，采用LSM-Tree的结构实现。LSM-Tree将磁盘的随机写转化为顺序写，从而大大提高了写速度。为了做到这一点LSM-Tree的思路是将索引树结构拆成一大一小两颗树，较小的一个常驻内存，较大的一个持久化到磁盘，他们共同维护一个有序的key空间。 CXL"},{"title":"WireShark 手册","date":"2023-06-03T09:24:26.305Z","url":"/2023/06/03/web/wireshark/","categories":[["manuals","/categories/manuals/"]]},{"title":"Mysql 手册","date":"2023-06-02T06:46:40.178Z","url":"/2023/06/02/web/mysql/","categories":[["manuals","/categories/manuals/"]],"content":"MySQL 授权与用户权限查询 MySQL赋予用户权限的命令的简单格式为 identified by在 MySQL 中，”identified by” 是用于创建或修改用户的密码认证方式的关键字。在创建或修改用户时，可以使用 “identified by” 指定用户的密码。例如，创建一个名为 “myuser” 的用户，并设置其密码为 “mypassword”，可以使用以下命令： 如果用户已经存在，可以使用以下命令修改其密码： 在这两个命令中，”identified by” 指定了用户的密码，并将其加密存储在 MySQL 的系统表中。当用户登录时，MySQL 将使用相同的加密算法对其输入的密码进行加密，并将其与存储在系统表中的密码进行比较。如果两者匹配，用户将被认为已通过身份验证，可以访问其被授权的数据库和表。 InnoDBInnoDB，是MySQL的数据库引擎之一，现为MySQL的默认存储引擎，为MySQL AB发布binary的标准之一。InnoDB由Innobase Oy公司所开发，2006年五月时由甲骨文公司并购。 InnoDB 的缓冲池"},{"title":"Ambari 手册","date":"2023-05-28T10:19:39.477Z","url":"/2023/05/28/hadoop/ambari/","categories":[["hadoop","/categories/hadoop/"]],"content":"1. 概念1.1. 概述Ambari 是 Apache 的开源项目。它是一种基于 Web 的工具，支持 Apache Hadoop 集群的创建、管理和监控。 Ambari 已支持大多数 Hadoop 组件，包括 HDFS、MapReduce、Hive、Pig、 Hbase、Zookeeper、Sqoop 和 Hcatalog 等；除此之外，Ambari 还支持 Spark、Storm 等计算框架及资源调度平台 Yarn。 Apache Ambari 从集群节点和服务收集大量信息，并把它们表现为容易使用的，集中化的接口：Ambari Web。 Ambari Web 显示诸如服务特定的摘要、图表以及警报信息，任何用户都可以查看Ambari Web 特性。可通过 Ambari Web 进行以下工作： 对 Hadoop 集群进行创建、管理、监控、添加主机、更新服务配置等； 利用 Ambari Web 执行集群管理任务，例如启用 Kerberos 安全以及执行 Stack升级； 拥有 administrator-level 角色的用户可以访问比 operator-level 或 view-only 的用户能访问的更多选项，例如，Ambari administrator 可以管理集群安全，一个 operator 用户可以监控集群，而 view-only 用户只能访问系统管理员授予他的必要的权限； 1.2. 体系结构Ambari 自身也是一个分布式架构的软件，主要由两部分组成：Ambari Server 和 Ambari Agent。简单来说，用户通过Ambari Server 通知 Ambari Agent 安装对应的软件；Agent 会定时地发送各个机器每个软件模块的状态给 Ambari Server，最终这些状态信息会呈现在 Ambari 的 GUI，方便用户了解到集群的各种状态，并进行相应的维护。 Ambari Server 从整个集群上收集信息。每个主机上都有 Ambari Agent，Ambari Server 通过 Ambari Agent 控制每个主机。 2. 操作2.1. YUM 安装 Ambari需要配置 YUM 源，如下。 安装 修改 ambari server 和 agent 的配置文件。其中 server 的配置文件中要指定 mysql 驱动的地址。 2.2. 启动 Ambari 操作界面 Web UI 服务 首先，去集群各个节点查看是否需要执行如下命令【一般 ambari-agent 是设置开机自启动的】，主要是启动 ambari-master。 然后浏览器访问 master 所在主机的 8080 端口。如果连接不上，启动失败，需要查看日志，如果发现是没连接上 MariaDB，需要先启动 MariaDB。 启动 MariaDB 服务。有时会发现通过常规的 systemctl 或者 service 启动不了，而且 &#x2F;etc&#x2F;init.d&#x2F; 下也没有启动脚本。 通过命令 &#x2F;usr&#x2F;libexec&#x2F;mysqld –user&#x3D;root 以 root 用户启动 mysqld。是通过查看目录 &#x2F;var&#x2F;log&#x2F; 下 mysql 的日志，才发现启动命令是 &#x2F;usr&#x2F;libexec&#x2F;mysqld。 然后再重新启动 ambari-master 和 ambari-agent。 2.3. 安装 HDP &amp; HDP-UTL3. 周边"},{"title":"Tomcat 源码分析","date":"2023-05-28T04:01:09.050Z","url":"/2023/05/28/web/tomcat_read/","categories":[[" ",""]]},{"title":"Common Algorithm and Examples","date":"2023-05-27T10:46:37.731Z","url":"/2023/05/27/algorithm/","categories":[[" ",""]],"content":"1. Common Algorithm2. Examples 将一个整数除符号位倒序输出为字符串形式 "},{"title":"ClickHouse 手册","date":"2023-05-27T04:28:50.817Z","url":"/2023/05/27/hadoop_ext/clickhouse/","categories":[["hadoop","/categories/hadoop/"],["clickhouse","/categories/hadoop/clickhouse/"]],"content":"1.基本概念2.批量写入数据 CK 不支持高并发写入，写入线程太多的话例如 150，可能会报异常 Too Many Part 等，我选择 10 线程并发写入； CK 更适合大批量写入，小批量写入性能反而不如大批量写入，批量写入条数最好不少于 8000，我选择的批量写入条数是 10000； 使用原生的 CK-JDBC 语句写入更快，我测的写入性能为 1290000 条&#x2F;秒【每条记录大小大概是几十字节】，当然每条记录越小写入速度越快； 批量写入数据的代码如下： ClickHouse 客户端建立的代码如下所示: "},{"title":"Java 实用知识点","date":"2023-05-27T04:01:33.804Z","url":"/2023/05/27/java/basic_concepts/java_notices/","categories":[["java","/categories/java/"],["java_basic_concepts","/categories/java/java-basic-concepts/"]],"content":" 有必要在ConcurrentHashMap前加上volatile吗? volatile&#x2F;synchronized&#x2F;原子类，区别和联系。 Java实体类中的基本类型成员变量默认值是0，引用类型默认值是null。所以如果使用&#x3D;&#x3D;判断基本类型long是否是null，是会报错的，应该将基本类型long改为相应的包装类Long。 shutdown&#x2F;awaitTermination&#x2F;shutdownNowshutdown 调用后，拒绝传入任务，不可以再 submit 新的 task，已经 submit 的将继续执行。awaitTermination(60,TimeUnit.SECONDS)，等待60秒，然后可执行自定义的任务，例如可以执行如下的 shutdownNow()。shutdownNow 调用后，将取消所有遗留的任务。 有缓存就可能存在数据一致性问题。"},{"title":"wheels","date":"2023-05-27T02:42:30.061Z","url":"/2023/05/27/wheels/","categories":[[" ",""]],"content":"1. 简介不要重复造轮子。该模块是一些可以复用的代码，包括工具类、处理逻辑类代码等，工具类就是为了帮我们减少重复性代码的，多用会使项目的可读性变得更高。至于这些工具包能干什么，可以通过他们的 Guide 稍微了解下都封装了什么功能。等到需要封装某个功能时，先看一下工具包的文档，找不到满足需求的功能时再自己实现。 2. 工具包 由 Apache 官方提供并维护的 Java 领域内比较出名的工具包:commons 由 Google 官方提供并维护的 Java 领域内比较出名的工具包:guava 由国人提供并维护的 Java 领域内比较出名的工具包:Hutool 日志系统(Java) 3. 示例3.1.1. 字节拼接使用现成的工具类 ByteArrayOutputStream。3.1.2. 单例模式 3.1.3. 多线程任务(生产者-消费者模式)消费者代码如下： 生产者代码如下： 组织者代码如下： 3.1.4. 后端服务读配置文件(Java、不在 Spring 框架下)例如配置文件 application.properties 内容如下: GetConfiguration 类代码如下: SetSystemProperty 类代码如下: 主类代码如下: 3.1.5. 遍历 Map，并过滤掉 value 为 null 的记录。 3.1.6. 拷贝数组(Java) 3.1.7. 文件和字节数组互相转化(Java) 3.1.8. 封装的同步栈数据结构(Java) 3.1.9. 自定义注解【注解就是标记，需要有相应的注解解析处理程序，可避免重复代码】3.1.9.1. 依据实体类创建相应的表注解 DBTable 定义如下，用于标记一个实体类，表示要创建该类的对应表。 注解 Constraints 定义如下，用于供其它注解使用，用于设置限制。 例如可以基于 Constraints 定义如下注解 Uniqueness。 注解 SQLInteger 定义如下，用于标记实体类的一个整数成员属性，将该属性映射为表的字段以及设置相应限制。 注解 SQLString 定义如下，用于标记实体类的一个字符串成员属性，将该属性映射为表的字段以及设置相应限制。 如下是注解解析处理程序，用于解析注解，并生成创建表语句。 对于如下一个标记有如上注解的实体类 Member，传入解析程序，就可自动生成建表语句。 3.1.10.创建目录或文件繁琐"},{"title":"Maven & Gradle 手册","date":"2023-05-26T15:08:35.468Z","url":"/2023/05/26/web/maven&gradle/","categories":[[" ",""]],"content":"1. Maven1.1. 相关概念1.2. 常见操作 打包 打包时跳过单元测试 或者在 pom.xml 中进行如下配置。 2. Gradle 7.22.1. 用户手册Gradle 是一种开源构建自动化工具，专注于灵活性和性能，Gradle 构建脚本是使用 Groovy 或 Kotlin DSL 编写的。 高度可定制——Gradle 以最基本的方式以可定制和可扩展的方式建模。 快速——Gradle 通过重用先前执行的输出，仅处理变化的输入以及并行执行任务来快速完成任务。 强大——Gradle 是 Android 的官方构建工具，支持许多流行的语言和技术。 2.2. 运行 Gradle Builds2.3. 编写 Gradle Builds2.3.1. 学习基本知识2.3.1.1. 编写构建脚本 基本概念: projects｜plugins｜tasks 注册一个简单的任务，名为 hello，然后在命令行执行 gradle -q upper。 可以声明依赖于其它任务的任务。 操纵现有任务。注册任务后，还可以通过 API 再次访问它们。例如，可以使用 API 在运行时动态地向任务添加依赖项。 Ant 就不允许这样的事情发生。 2.4. 编写 JVM Builds2.5. 使用依赖项2.6. 编写 C++｜Swift Builds2.7. 扩展 Gradle2.8. 参考2.9. Gradle 常用命令"},{"title":"Ranger 手册","date":"2023-05-24T11:56:44.040Z","url":"/2023/05/24/hadoop/ranger/","categories":[["hadoop","/categories/hadoop/"]]},{"title":"常用工具网址导航","date":"2023-05-22T03:51:36.292Z","url":"/2023/05/22/tools_link/","categories":[[" ",""]],"content":"词典｜翻译韦氏大词典牛津词典剑桥词典小牛翻译谷歌翻译 资源链接广告人的网址导航字体下载网站ARP 8.0 苹果版【密码:f8yi】 Hexo + GitHub 搭建个人博客搭建教程参考的hexo主题样式 问答网站IT技术问答外文网站-StackOverFlowIT技术问答-稀土掘金IT技术问答-Segmentfault 思否IT技术问答-CSDNIT技术问答-博客园ChatGPT [会议&#x2F;组织]主页UsenixSigIRSigModICDEApache Projects 技术教程极客教程鸟哥的Linux私房菜中国大学慕课力扣廖雪峰网站Java教程网站-BaeldungSpringCloud中文网Git教程 处理工具提取图片中的文字Base64和图片相互转换删除图片背景站长工具（工具汇总，可能包含其它已有工具） 论文搜索与下载谷歌学术知网Sci-Hubdblp"},{"title":"Vim 手册","date":"2023-05-21T10:10:13.263Z","url":"/2023/05/21/vim/","categories":[["manuals","/categories/manuals/"]],"content":"1.概念vim 是最出名的 Linux 的文本编辑器。centos 下 yum install vim 安装 vim。 2.命令2.1.全文搜索 2.2.显示行号 2.3.跳到文本末尾 2.4.批量删除多行数据 2.5.保存并退出Vim｜不保存退出Vim 2.6.插入模式｜退出插入模式 2.7.光标快速移到行首｜行尾 2.8.删除光标所在行内容｜恢复 2.9.复制光标所在行的内容｜粘贴 2.10.回到上一步 2.11.查找并替换"},{"title":"FTP 手册","date":"2023-05-21T10:04:35.186Z","url":"/2023/05/21/web/ftp/","categories":[["manuals","/categories/manuals/"]],"content":"1. 概念FTP 只通过 TCP 连接，没有用于 FTP 的 UDP 组件。FTP 不同于其他服务的是它使用了两个端口，一个数据端口和一个命令端口(或称为控制端口)。通常 21 端口是命令端口，20 端口是数据端口。 1.1. 安装 ftp 1.2. ftp | sftp | vsftpftp 是 file transfer protocol 的缩写，文件传输协议，用于在网络上进行文件传输的一套标准协议，使用客户&#x2F;服务器模式。它属于网络传输协议的应用层。sftp 是 secure file transfer protocol 的缩写，安全文件传输协议，是 ssh 服务的一项子服务，所以端口也是 22，用户和密码和 ssh 一致。vsftp 是一个基于 GPL 发布的类 Unix 系统上使用的 ftp 服务器软件，它的全称是 very secure ftp，从此名称可以看出来，编制者的初衷是代码的安全。 1.3. PORT主动模式 &amp; PASV被动模式当混入主动&#x2F;被动模式的概念时，数据端口就有可能不是 20 了。 PORT 主动模式的连接过程是：客户端向服务器的命令端口（默认是21）发送连接请求，服务器接受连接，建立一条命令链路。当需要传送数据时， 客户端在命令链路上用 PORT 命令告诉服务器：我打开了某个端口 A，你过来连接我。于是服务器从 20 端口向客户端的 A 端口发送连接请求，建立一条数据链路来传送数据。 PASV 被动模式的连接过程是：客户端向服务器的命令端口（默认是21）发送连接请求，服务器接受连接，建立一条命令链路。当需要传送数据时， 服务器在命令链路上用 PASV 命令告诉客户端：我打开了某个端口 B，你过来连接我。于是客户端向服务器的 B 端口发送连接请求，建立一条数据链路来传送数据。当客户端通知服务器它处于被动模式时才启用。 可能产生的问题是，PASV 被动模式下，FTP 服务器每次可能开启不同的端口来传输数据，但是可能由于 Linux 安全限制，例如防火墙，FTP 客户端无法访问这些端口，就无法建立数据链路进行数据传输了。 主动FTP对FTP服务器的管理有利，但对客户端的管理不利。因为FTP服务器企图与客户端的高位随机端口建立连接，而这个端口很有可能被客户端的防火墙阻塞掉。被动FTP对FTP客户端的管理有利，但对服务器端的管理不利。因为客户端要与服务器端建立两个连接，其中一个连到一个高位随机端口，而这个端口很有可能被服务器端的防火墙阻塞掉。幸运的是，有折衷的办法。既然FTP服务器的管理员需要他们的服务器有最多的客户连接，那么必须得支持被动FTP。我们可以通过为FTP服务器指定一个有限的端口范围来减小服务器高位端口的暴露。这样，不在这个范围的任何端口会被服务器的防火墙阻塞。虽然这没有消除所有针对服务器的危险，但它大大减少了危险。 1.4. FTP 连接和 HTTP 连接FTP 连接和 HTTP 连接不一样，FTP 连接是要登录验证的。FTP 连接数是有上限的。 2. 命令2.1. 登录 FTP 2.2. 删除指定的文件 2.3. 删除目录下全部文件 2.4. 删除目录下多个符合条件的文件 3. 周边3.1. FTP 客户端连接代码 3.2. 多线程持续往 FTP 中写数据用到了生产者-消费者模式，以下是消费者代码。 生产者代码如下。 "},{"title":"Git 手册","date":"2023-05-21T09:04:29.054Z","url":"/2023/05/21/git/","categories":[["manuals","/categories/manuals/"]],"content":"1. 概念1.1. Git 和 GitHub 关系Git 是源代码的版本管理工具，类似地还有 SVN&#x2F;VSS&#x2F;VCS。GitHub 是一个网站，允许广大的开发者通过 Git 上传代码。 1.2. Mac自带Git｜HomeBrew安装GitMac 系统自带 git，放在了 &#x2F;usr&#x2F;bin 目录下。但往往版本过于老旧，可以通过 homebrew 安装最新的git，路径为 &#x2F;usr&#x2F;local&#x2F;Cellar&#x2F;git&#x2F;2.20.1，然后将默认 git 指向到 homebrew 新安装的 git。 1.3. 四种类型的 object在 git 的世界里，有四种类型的 object，分别是：tree、blob、commit、tag。笼统地说，tree 代表的是目录结构，或者简单地理解为代表一个目录。blob 用来存储文件内容， 或者说表示一个文件。commit 存储一次提交的信息，包括所在的tree，parent是谁，作者及message等信息。tag 就是标签的意思， 实际就是commit的别名。 git 之所以能够作为版本控制系统，是因为GIT会把对文件的每次修改结果作为一个对象保存起来。 1.4. origin｜HEAD｜master origin：是 Git 中默认的远程仓库名称，它通常指向存储代码的远程服务器。当我们通过 git clone 命令克隆一个 Git 仓库时，Git 会自动设置一个默认的远程仓库，名称为 origin。 HEAD：HEAD 是 Git 中表示当前分支的指针，它指向当前所在的分支，可以理解为”当前分支的别名”。当我们切换分支时，HEAD 指针会自动指向新的分支。 master：master 是 Git 中默认的主分支名称。当我们在一个新的 Git 仓库中创建了第一个提交时，Git 会自动创建一个名为 master 的分支，并将 HEAD 指向此分支。 我们可以自定义远程仓库名称、分支名称以及默认主分支名称。 1.5. 默认主分支名称在 Git 2.28 版本之前，Git 的默认主分支名称为 master。但是，由于 master 这个词汇的含义可能会引起争议和不适，以及对历史背景的负面影响，因此 Git 官方决定将默认主分支名称更改为 main。因此，如果使用的是 Git 2.28 版本及以上，使用 git branch -M main 命令可以将当前分支名称更改为 main，以符合默认设置。 1.6. 通过ssh方式上传代码通过命令生成公钥&#x2F;私钥文件，私钥自己留着，公钥给 GitHub 网站。实现不需要验证用户名密码就能上传代码。生成公钥和私钥 然后进入公钥和私钥，将公钥中的内容复制，进入 GitHub 用户中心setting，创建一个新的ssh，将内容复制进去。就可以用仓库的ssh上传了。 1.7. 设置当前使用的用户就是在 git 中设置当前使用的用户是谁，每次备份都把当前备份者的信息存储起来，命令如下。 –global 参数表示设置全局用户配置，即对 Git 仓库中的所有项目都生效。如果要设置本地用户配置，可以去掉 –global 参数，并在需要的 Git 仓库中单独设置。设置用户姓名和电子邮件地址后，Git 就可以将这些信息作为提交记录的作者和提交者信息。这样，其他人就可以通过这些信息来了解谁提交了哪些修改。需要注意的是，在设置用户配置时，用户姓名和电子邮件地址应该与您的实际信息一致，以便其他人可以识别和联系到您。同时，如果您在多个 Git 仓库中使用不同的身份，可以为每个 Git 仓库单独设置用户配置，以避免混淆。 1.8. git reset 参数git reset 命令只适用于本地仓库，如果想要撤销已经推送到远程仓库的提交，应该使用 git revert 命令。git reset 命令用于将当前分支的 HEAD 指针指向指定的提交，并可以选择是否更新工作区和索引。具体来说，git reset 命令有以下几种常见的参数： --soft：只重置 HEAD 指针，不更新工作区和索引。此时，之前的更改会保留在工作区和索引中，但是 HEAD 指针会指向之前的提交，相当于撤销之前的提交。 --mixed：重置 HEAD 指针，并更新索引，但不更新工作区。此时，之前的更改会保留在工作区中，但是索引会被更新为之前的提交，相当于取消之前的提交并将更改暂存。 --hard：重置 HEAD 指针，并更新工作区和索引。此时，之前的更改会被全部删除，并恢复到重置后的状态，相当于彻底取消之前的提交并删除之前的更改。因此，--hard 参数是一种比较危险的操作，因为它会彻底删除之前的更改，包括未提交的更改。如果使用不当，可能会导致数据丢失。在使用 --hard 参数时，需要特别小心，并确保已经备份了所有重要的更改。 1.9. git log 和 git reflog 的区别git log 和 git reflog 都是 Git 中用于查看提交记录的命令，区别如下。 显示的提交记录不同：git log 显示的是当前分支的提交历史，包括所有已经提交的更改记录，而 git reflog 显示的是当前仓库 HEAD 指针的变化历史，包括所有的提交、分支合并、重置等操作记录。 显示的信息不同：git log 显示的提交记录包括提交的作者、提交时间、提交信息等详细信息，而 git reflog 显示的是 HEAD 指针的变化记录，包括变化时间、变化前后的指针位置等信息。 作用不同：git log 主要用于查看提交历史，以便了解代码的修改情况和版本演化过程，而 git reflog 主要用于恢复误操作或者回退到之前的某个状态，以便在代码回滚或者分支合并等操作中更好地控制状态。因此，git log 和 git reflog 在实际使用中有不同的用途，可以根据需要选择不同的命令进行查看。如果想要了解代码的版本演化过程和详细信息，可以使用 git log 命令；如果想要恢复误操作或者回滚到之前的某个状态，可以使用 git reflog 命令。 1.10. Remote &amp; Repository &amp; Workspace 的关系(Remote) ——————————-pull————————————&gt;||——–fetch&#x2F;clone——–&gt;(Repository)—————Checkout———-&gt;Workspace|&lt;——–push——————–|&lt;——–commit——–(index)&lt;————-| 2. 命令2.1. 有关于「编辑状态」的内容 查看状态 显示具体修改的内容 2.2. 有关「分支」的操作 创建分支「刚创建的分支内容和 master 内容是一样的」 查看当前有哪些分支 重命名分支将当前分支的名称更改为 main，并更新 Git 仓库中的所有引用（例如 HEAD 引用和远程跟踪分支）以反映该更改。应该确保当前分支确实是主分支，并且没有其他分支基于当前分支进行了提交。否则，该命令可能会丢失提交历史，并导致数据丢失。 切换分支 合并分支「合并当前分支和指定分支，如果存在冲突，需要手动处理」 将新建的分支推送到远程仓库中 删除主机的分支 查看本地分支和远程分支的关联情况 复制其它分支的多个提交 commit 到当前分支git cherry-pick 的作用是合并其它分支的若干个 commit 到当前分支，这些若干个 commit 代码提交可以是其它分支的 commit 提交。例如：当前 master 分支打算把 develop 分支的 C、D、E 这三次提交复制到当前 master 分支。首先需要从 develop 切换到分支 master。 然后执行 cherry-pick。 其中 C、D、E 三次提交的 commit-id 可以在 develop 分支下通过 git log 查看。 2.3. 有关于「暂存」的操作 场景：正写代码，又想拉取新代码，但不想提交正在写的代码 查看所有的暂存 清空所有的暂存 2.4. 有关于「仓库」的操作 初始化本地仓库 显示所有的远程仓库 查看远程仓库别名 显示某个远程仓库的信息 修改仓库名 将创建的本地 git 仓库和分支同步到远程 删除远程库删除其实是解除了本地和远程的绑定关系，并不是物理上删除了远程库。远程库本身并没有任何改动。要真正删除远程库，需要登录到GitHub，在后台页面找到删除按钮再删除。 2.5. 有关于「历史版本代码」的操作 查看日志 查看操作历史 回退到某个历史版本代码 只是修改上次提交的代码，做一次更完美的 commit git reset commitId 和 git reset –hard commitId 的差别 2.6. 有关于「代码上传下载」的操作 克隆项目代码「第一次，会得到远程仓库相同的数据，如果多次执行会覆盖本地内容」 场景：试图将内网中的 git 服务器上的项目代码克隆到本地。 拉取代码「会将远程分支的数据得到（注意本地要初始一个仓库），pull不会覆盖，而是合并」 把代码存储到 .git 仓库中会将当前目录下所有改动的文件放到大门口。 将所有修改后的文件直接放入仓库房间，即版本库。 推送代码git push 用于从将本地的分支版本上传到远程并合并。 推送代码 git push 的 -u 参数git push 将本地分支 main 推送到远程仓库 origin 中名为 main 的分支。如果远程仓库中不存在该分支，则会自动创建。使用 -u 选项将本地分支 main 设置为远程跟踪分支，以便在以后的推送和拉取操作中自动关联远程分支和本地分支。需要注意的是，在使用 git push -u 命令时，我们需要先进行一次初始推送，以建立本地分支和远程分支的关联。在以后的推送和拉取操作中，我们就可以使用 git push 和 git pull 命令，而不需要指定远程分支的名称。 发起「合并分支」请求先 git merge 目标分支;然后再 git push;点击链接发起请求。 "},{"title":"HDFS 手册","date":"2023-05-20T13:27:02.401Z","url":"/2023/05/20/hadoop/hdfs/","categories":[["hadoop","/categories/hadoop/"]],"content":"1. 概念1.1. hdfs dfs 和 hadoop fs 区别? hadoop fs 用的面最广，可以操作任何文件系统，这里 fs 泛指文件系统。 hdfs dfs 特定用于 HDFS。 1.2. HDFS 和 MapReduceHadoop 的框架最核心的设计就是：HDFS 和 MapReduce。HDFS 为海量的数据提供了存储，而 MapReduce 为海量的数据提供了计算。HDFS 可以理解为一个分布式的、有冗余备份的、可以动态扩展的用来存储大规模数据的大硬盘；而 MapReduce 则理解为一个计算引擎，按照 MapReduce 的规则编写 Map &#x2F; Reduce 计算的程序，可以完成计算任务。HDFS 是一个分布式文件系统，引入存放文件元数据信息的服务器 Namenode 和实际存放数据的服务器 Datanode，对数据进行分布式储存和读取；而 MapReduce是一个计算框架，MapReduce 的核心思想是把计算任务分配给集群内的服务器里执行，先对计算任务进行拆分【Map 计算 &#x2F; Reduce 计算】，再借助任务调度器 JobTracker 对任务进行分布式计算。 1.3. 配额HDFS 允许管理员为每一个用户和每一个文件夹设置配额：命名配额和空间配额。name quota：该目录下的名字数量做硬性限制，为文件夹下的数量作出的限制,超过限制则会报错：quota exceed，最大值配额:Long.MAX_Valus。新创建的文件夹没有分配quota。space quota：设置一个文件夹的大小，如果超过则块写入会失败（副本也算）。最大的配额：Long.Max_Value。配额设置为0还是运行文件创建，但是不能向文件中写入块。文件夹不使用主机文件系统不计算在空间配额里面，主机文件系统用来记录文件源数据的数据不算在配额中。 1.4. 安全模式HDFS 的 block 丢失过多会进入安全模式。需要先退出安全模式，然后检测、修复或删除坏块。 1.5. 纠删码HDFS可以直接启用纠删码吧？可以。 1.6. NameNode 的 Java 堆 HeapHDFS的NameNode的Java 堆Heap 大小可以适当调大，在Ambari上-HDFS-配置-Advanced-General处调整。 1.7. 事务大多数文件系统没有事务的概念。强一致性的数据并不适合存储在HDFS上，HDFS本身不支持事务性操作。HDFS不支持事务处理的主要原因是其数据访问模型。HDFS采用的是一种写一次、读多次的模型，即文件写入后不能再修改。因此，如果要支持事务处理，则需要对数据进行修改，这与HDFS的设计初衷相违背。但是可以通过在HDFS之上构建事务性应用程序来实现事务。事务性应用程序通常需要使用一些分布式事务协议，如2PC（Two-Phase Commit）协议或Paxos协议等，来协调多个节点上的操作，以实现事务的提交和回滚操作，从而确保数据的一致性和可靠性。如果需要在HDFS上实现事务性应用程序，可以使用一些开源工具，如Apache HBase、Apache Phoenix、Apache Hive等。这些工具提供了一些事务性操作，如ACID（原子性、一致性、隔离性和持久性）事务、乐观并发控制（Optimistic Concurrency Control，OCC）和MVCC（Multi-Version Concurrency Control）等，来满足不同的业务需求。 2. 命令2.1. 将 HDFS 中文件下载到本地 2.2. 查看某个目录下的所有文件 2.3. 删除某个目录下所有文件 2.4. 创建某个文件夹 2.5. 创建某个文件 2.6. 上传某个文件 2.7. 查看文件夹的配额 2.8. 手动设置某个目录下所有文件的副本数"},{"title":"Redis 内存数据库","date":"2023-05-20T13:24:20.764Z","url":"/2023/05/20/hadoop_ext/redis/","categories":[["hadoop","/categories/hadoop/"],["redis","/categories/hadoop/redis/"]],"content":"1. 相关概念1.1. 与 memcache 比较与缓存服务器 memcache 对比，redis 的一大优势就是支持数据的持久化，而 memcache 一旦重启，内存中保存的数据就完全消失了。 1.2. 支持的数据类型redis 不仅可以存储普通的字符串键，共支持五种数据类型： string（字符串） hash（哈希） list（列表） set（集合） zset(sorted set：有序集合) 1.3. 主从复制为了扩展Redis的读性能和为Redis提供故障转移支持，实现了主从复制特性：主服务器与从服务器。执行复制的从服务器会连接上主服务器，接受主服务器发送的整个数据库的初始副本，之后主服务器执行的写命令，都会发送给所有的从服务器去执行，从而实时的更新从服务器的数据集，从服务器包含的数据会不断地进行更新，所以客户端可以向任意一个从服务器发送读请求，以此来避免对主服务器进行集中式的访问。 1.4. 持久化拥有两种不同形式的持久化方法。快照RDB和只追加文件AOF。一种是时间点转储(point-in-time dump)，；一种是将所有修改了数据库的命令都写入一个只追加文件里面，用户可以根据数据的重要程度，将只追加写入 设置为从不同步&#x2F;每秒钟同步一次&#x2F;每写入一个命令就同步一次。AOF持久化会将被执行的写命令写到AOF文件的末尾，以此来记录数据发生的变化。因此，Redis只要从头到尾重新执行一次AOF文件包含的所有的写命令，就可以恢复AOF文件所记录的数据集。 1.5. 数据分片分片是一种将数据划分为多个部分的方法，对数据的划分可以基于键包含的ID、基于键的散列值，或者基于以上两者的某种组合。通过对数据进行分片，用户可以将数据存储到多台机器里面，也可以从多台机器上面获取数据，这种方法在解决某些问题的时候可以获得线性级别的性能提升。 1.6. 选用场景是否选择 redis 要根据具体的情况，如果程序对性能的要求不高，又或者因为费用原因而没有办法将大量的数据存储到内存里面，那么可能就不需要使用 redis。 1.7. redis 数据结构 SDSC 字符串和 redis 的 SDS（simple dynamic string） 1.8. 多个数据库单机 redis 情况下： redis 是一个字典结构的存储服务器，而实际上一个 redis 实例提供了多个用来存储数据的字典，客户端可以指定将数据存储在哪个字典中，这与我们熟知的在一个关系数据库实例中可以创建多个数据库类似，可以将其中的每个字典都理解成一个独立的数据库。 redis 数据库的数量是固定的，并在配置文件中设置，默认情况下，有16个数据库，且每个数据库都由一个数字（而不是名称）来标识。 redis 不支持自定义数据库的名字，每个数据库都以编号命名，开发者必须自己记录哪些数据库存储了哪些数据。 redis 也不支持为每个数据库设置不同的访问密码，所以一个客户端要么可以访问全部数据库，要么连一个数据库也没有权限访问。 redis 多个数据库之间并不是完全隔离的，比如 FLUSHALL 命令可以清空一个 redis 实例中所有数据库中的数据。综上，redis 的这些数据库更像是一种命名空间，而不适宜存储不同应用程序的数据。比如可以使用0号数据库存储某个应用生产环境中的数据，使用1号数据库存储测试环境中的数据，但不适宜使用0号数据库存储A应用的数据而使用1号数据库B应用的数据，不同的应用应该使用不同的 redis 实例存储数据。由于 redis 非常轻量级，一个空 redis 实例占用的内存只有 1M 左右，所以不用担心多个 redis 实例会额外占用很多内存。 redis 集群情况下： redis 支持多个数据库，并且每个数据库的数据是隔离的不能共享，但是基于单机才有，如果是集群就没有数据库的概念。 1.9.单线程redis 是单线程处理请求的。 2. 命令2.1. 查看有多少个DB 2.2. 切换DB 2.3. 清除某个库中的所有数据 2.4. 查看键 key_name 所占的存储空间 Redis缓存问题 Redis命令"},{"title":"ES Common CMDS","date":"2023-05-18T11:48:52.113Z","url":"/2023/05/18/hadoop_ext/es/basic_concepts/es_common_cmds/","categories":[["hadoop_ext","/categories/hadoop-ext/"],["es","/categories/hadoop-ext/es/"],["es_basic_concepts","/categories/hadoop-ext/es/es-basic-concepts/"]],"content":"1.查看 ES 集群所有的索引 2.查看 ES 集群的健康情况 3.查看 ES 集群所有节点信息【信息比较全面】 4.查看 ES 集群主节点 5.查看某个索引的动态映射信息 6.模糊查询 7.返回符合条件的文档数有时候我们不需要满足条件的原始文档数据，而是需要返回符合条件的文档数，类似于mysql的select count(*)查询条数，es中进行count查询的api的endpoint为”_count”“_count”支持多个索引同时查询符合条件的匹配数 布尔查询 3. 周边 《Elasticsearch 权威指南》中文版 Elasticsearch SQL工具能够用SQL语句的方式来与ES进行交互，例如多条件索引过滤查询等，确实挺好用的。 1. Index｜Type｜Document Index-库 Type-表 Document-数据 "},{"title":"JVM 调优手册","date":"2023-05-17T12:24:11.506Z","url":"/2023/05/17/java/jvm/","categories":[["java","/categories/java/"],["java_advanced","/categories/java/java-advanced/"]],"content":"Java GC机制"},{"title":"ZooKeeper","date":"2023-05-16T05:21:19.335Z","url":"/2023/05/16/hadoop/zookeeper/","categories":[["hadoop","/categories/hadoop/"],["zookeeper","/categories/hadoop/zookeeper/"]],"content":"hbase:mate 表所在的RegionServer 信息被存储到了zookeeper 中的 &#x2F;hbase&#x2F;meta-region-server 节点 客户端命令行客户端连接服务 删除某个节点路径"},{"title":"HBase Data Model","date":"2023-05-15T17:54:41.685Z","url":"/2023/05/16/hadoop/hbase/basic_concepts/hbase_data_model/","categories":[["hadoop","/categories/hadoop/"],["hbase","/categories/hadoop/hbase/"],["hbase_basic_concepts","/categories/hadoop/hbase/hbase-basic-concepts/"]],"content":"1. 概念1.1.数据存储路径hdfs 的配置文件中 hbase.rootdir 属性，是 hbase 数据存储的路径。 1.2.稀疏存储HBase 是稀疏的，不像 Mysql 那样需要用 Null 表示空值，HBase 的空值是不需要存储的。 1.3.事务性操作Hbase在一个region上的多行操作是原子的。 Hbase列数据默认可以保存3个版本"},{"title":"Nodejs & Npm 的关系","date":"2023-05-15T17:47:09.363Z","url":"/2023/05/16/web/nodejs&npm/","categories":[[" ",""]],"content":"1.问题我们知道，JavaScript 的出现可以说是 Java Applet 的掘墓人，它因为是浏览器原生支持的，无需像 Applet 那样还要额外安装 Applet 相关程序，一来很方便，二来执行效率也比后者要高很多，它也同样能满足请求后端服务、实现动态网页的需求。 可 JavaScript 不满足于只做一个前端页面和后端服务交互的脚本语言，我 JS 自己也想开发后端服务。在前端因为有浏览器原生支持所以 JS 才得以运行，但是在服务器端怎么执行 JS 的代码？就像 PHP 和 Python 脚本，能做为后端语言也是因为有解释器的支持。 2.方案既然浏览器能支持 JS 的执行，那我就利用一下浏览器内核引擎，再加点自己的东西，于是有了 Nodejs。 Nodejs 是对 Chrome V8 引擎的封装，从而可以支持 JavaScript 的运行，也就是说，Nodejs 与谷歌浏览器在解析JavaScript 时都使用了V8引擎。Nodejs 不是一个 JS 文件，而是一个 JS 的运行环境，是一个 JS 的开发平台。作为开发平台，它当然提供了诸多的 API 来满足不同的业务需求。Nodejs 使得 JavaScript 能够运行于服务端，并使其成为地位与服务端语言（Python、PHP 等）一样高的脚本语言。 Nodejs 的能力 提供了替代的API，使得 V8 引擎在非浏览器的环境下运行地更好； V8 引擎执行 JavaScript 的速度非常快，性能非常好； 是一个基于 Chrome JavaScript 运行时建立的平台，能方便地搭建响应速度快、易于扩展的网络应用。 现在 JS 的开发平台已经搭建起来了，可是在开发网站时往往依赖的库很多，例如依赖的 jquery、bootstrap 库等都需要自己去不同的地方单独下载，并导入工程。就很麻烦，而且不好管理版本，所以为什么不用管理工具来统一管理这些资源？ 于是 Npm 就来了，Npm 全称是 Node package manager（Node 包管理工具），和 Maven、Gradle 一样是个包管理工具，只不过 Maven 与 Gradle 是用来管理 Java jar包的，而 Npm 是用来管理 Node 包的。 Npm 的实现原理与 Maven&amp;Gradle 一样。 先建立一个远程代码仓库，用来存放所有的被共享的 Node 库，并且每个 Node 库都有自己唯一的标识符； 用户想要引入某个 Node 库时，只需引用对应的标识符，就会自动下载下来。 Npm 一开始出来的时候，并没有人在意它。后来 Nodejs 开发完成后，正缺少一个包管理工具，于是二者一拍即合。结果就是 Nodejs 内置了Npm，这也导致了要下载 Npm 的话，必须得下载 Nodejs。随着 Nodejs 流行，很多人开始使用Npm 下载和共享代码，Npm 已经成了前端的标配。 3.Npm常见操作3.1.Npm源"},{"title":"YCSB测试HBase读写性能","date":"2023-05-15T14:38:58.053Z","url":"/2023/05/15/ycsb/","categories":[[" ",""]],"content":"1.测试类型基准测试 micro-benchmark（微基准测试）是基准测试中的一种方法，是一种用于测量计算机程序性能的测试方法。它通常用于测量计算机程序在解决很小的问题时的运行时间，比如执行单个函数或算法的时间。micro-benchmark 可以用来精确测量一个程序的各个部分的性能，并帮助开发人员找出瓶颈所在，从而优化程序的性能。 压力测试 2.YCSB测试命令"},{"title":"HBase Problems Encountered","date":"2023-05-14T15:07:42.146Z","url":"/2023/05/14/hadoop/hbase/hbase_problems/","categories":[["hadoop","/categories/hadoop/"],["hbase","/categories/hadoop/hbase/"],["hbase_advanced","/categories/hadoop/hbase/hbase-advanced/"]],"content":"1.hbase:meta is not online 停止 HBase 服务; 删除 Zookeeper 上 HBase 对应的节点; 删除 HDFS 上 MasterWAL 目录下的日志文件; 重启 HBase 服务; 2.hbase:namespace is not online 删除 hbase:namespace 及相关的所有 region 在 hbase:meta 表中的所有记录; 删除 HDFS 上 hbase:namespace 对应的目录下的数据; 重启 HBase 服务; 3.Not running balancer because 265 regions found not on an online server.问题表现： hbase:meta 表和 hbase:namespace 表都在线; 且通过 HMaster 的 Web 监控界面显示所有表的 region 都 online; 但是 regionserver 模块所有的 regionserver 的 Num.Regions 都为 0;解决方法： 将 hbase:meta 表中所有的 region 的 info:state 值都修改成 OFFLINE，修改方法可以通过写SH脚本的方法实现; 清理 HMaster 的 MasterWAL 目录下的日志文件数据; 然后重启 HBase 服务; 4.使用 YCSB 测试 HBase 的 TPS，TPS 只有几百，且 HBase 的数据不落盘、只刷写几MB数据。HBase 不进行 region 的均衡操作。&#x3D;&gt;集群内部网络存在问题，出现丢包10%以内的现象。&#x3D;&gt;HBase 不写数据。 5.永久 Region In TransitionHbase永久RIT异常： 5.1.HMaster 是否出现内存中信息不一致问题 修改表 hbase:meta 中 region 的状态信息为 OFFLINE。 清除 HDFS 上 MasterWAL 目录下的日志数据。 并重启 HBase 服务。 5.2.HBase 是否出现数据一致性问题 通过 hbase hbck 检查出几张表存在 inconsistent 的问题，具体报错如下。 5.3.HDFS 数据是否出现问题 发现有 DataNode 节点挂掉。重启挂掉的 DataNode 节点，如果通过 Ambari 无法快速定位有问题的 DataNode 节点，可以使用如下命令显示所有 Datanode 健康状态，快速找到问题 DataNode 节点。 检查数据健康情况。 删除数据坏块。发现 MISSING BLOCKS 有 98 个，CORRUPT FILES 有 93 个，CORRUPT BLOCKS 有 3 个，因为又是一副本存的，所以修复没什么意义。 如果报错 HDFS 中的数据块 Block 找不到对应的 DataNode 管理。如果检测没有坏块问题，可能是 NameNode 出现了信息不一致问题，可以尝试重启 NameNode。 5.4.再走一遍5.1流程。6.删除表报错问题表现：hbase shell 中将某个表状态修改为了 CLOSED，但是 drop 删除时报错，称需要先 disabled。 先查看表 hbase:meta 中指定表的状态，发现为 disabling。 修改表状态为 disabled。 7.编译 HBase 源码报错 “enforce (hadoop3-profile-required)”插件 maven-enforce使用 JDK11 编译源码要求 profile 为 Hadoop3，但是我要编译的是分支 branch-2.5 的源码。可以调整 JDK 为 JDK8。"},{"title":"Linux 手册","date":"2023-01-02T10:13:43.466Z","url":"/2023/01/02/linux_cmds/","categories":[["manuals","/categories/manuals/"]],"content":"1. 概念 Linux 一切皆文件。 符号｜在 Linux 中是管道的意思，前一步处理的结果传入下一步处理，所以不同的命令可以通过｜结合使用。 ～ 与 &#x2F;home，～ 是当前用户的家目录，&#x2F;home 是家目录。 常见的文件目录功能： &#x2F;dev，dev 是 device的英文缩写。&#x2F;dev 这个目录对所有的用户都十分重要，因为在这个目录中包含了所有Linux系统中使用的外部设备。但是这里并不是放的外部设备的驱动程序，这一点和 windows,dos 操作系统不一样。它实际上是一个访问这些外部设备的端口。我们可以非常方便地去访问这些外部设备，和访问一个文件，一个目录没有任何区别。设备文件一般存放在 &#x2F;dev 目录下，设备文件分为两种：块设备文件(b)和字符设备文件(c)。&#x2F;dev&#x2F;null，该设备是空设备，也称为位桶（bit bucket）或者黑洞(black hole)。你可以向它输入任何数据，但任何写入它的数据都会被抛弃。通常用于处理不需要的输出流。（当然，它也可以作为空的输入流）&#x2F;dev&#x2F;zero，该设备无穷尽地提供空字符（ASCII NUL, 0x00），可以使用任何你需要的数目。它通常用于向设备或文件写入字符串0，用于初始化数据存储。（当然，也可作为输出流的接受容器）。 &#x2F;etc 配置目录 &#x2F;usr 用户程序目录 &#x2F;tmp 临时目录 &#x2F;bin 用户二进制 &#x2F;sbin 系统二进制 &#x2F;usr&#x2F;bin 集中了几乎所有用户命令，是系统的软件库，另有些命令在 &#x2F;bin 或 &#x2F;usr&#x2F;local&#x2F;bin 中 主目录：&#x2F;root、&#x2F;home&#x2F;username 用户可执行文件：&#x2F;bin、&#x2F;usr&#x2F;bin、&#x2F;usr&#x2F;local&#x2F;bin 系统可执行文件：&#x2F;sbin、&#x2F;usr&#x2F;sbin、&#x2F;usr&#x2F;local&#x2F;sbin 其他挂载点：&#x2F;media、&#x2F;mnt 内核和Bootloader：&#x2F;boot 服务器数据：&#x2F;var、&#x2F;srv 系统信息：&#x2F;proc、&#x2F;sys 共享库：&#x2F;lib、&#x2F;usr&#x2F;lib、&#x2F;usr&#x2F;local&#x2F;lib 压缩文件 .tar｜.tar.gz｜.zip.tar 是格式压缩，.tar.gz 是进一步压缩的二次压缩。.tar.gz 压缩格式用于 Unix 操作系统，而 Zip 用于 Windows 操作系统。 tar：tar是*nix下的打包工具，生成的包通常也用tar作为扩展名，其实tar只是负责打包，不一定有压缩，事实上可以压缩，也可以不压缩，通常你看到xxxx.tar.gz，就表示这个tar包是压缩的，并且使用的压缩算法是GNU ZIP，而xxxx.tar.bz2就表示这个包使用了bzip2算法进行压缩，当然这样的命名只是一种惯例，并非强制。简单地说，tar就仅是打包。 jar：即Java Archive，Java的包，Java编译好之后生成class文件，但如果直接发布这些class文件的话会很不方便，所以就把许多的class文件打包成一个jar，jar中除了class文件还可以包括一些资源和配置文件，通常一个jar包就是一个java程序或者一个java库。 war：Web application Archive，与jar基本相同，但它通常表示这是一个Java的Web应用程序的包，tomcat这种Servlet容器会认出war包并自动部署。 tar是通用的另一种打包格式，为了部署到服务器时方便。而jar是java app server识别的java部署格式，其实是Zip文件，只是内部的文件有规范。war是专用于web app的jar。另外还有用于enterprise app的ear后缀。 scp 和 sftp 两者都是基于 ssh 安全协议的文件传输命令； scp 比较简单，是轻量级的，sftp 的功能则比较多； sftp 在文件传输过程中中断的话，连接后还可以继续传输，但 scp 不行； Linux 环境变量 按照生命周期来分，可以分为两类：永久的：需要用户修改相关的 profile 配置文件，source 重新加载，变量永久生效。临时的：用户利用 export 命令，在当前终端下声明环境变量，关闭 shell 终端失效。 按照作用域来分，也可以分为两类：系统环境变量：系统环境变量对该系统中所有用户都有效。用户环境变量：这种类型的环境变量只对特定的用户有效。 Unix &#x2F; Linux 中有两个 profile 文件 &#x2F;etc&#x2F;profile，是全局 profile 文件，设置后会影响到所有用户。 &#x2F;home&#x2F;username&#x2F;.profile 或 &#x2F;home&#x2F;username&#x2F;.bash_profile，是特定用户的环境变量。 补充：profile 文件是 Unix 上才有的；.bash_profile 文件是 Linux 下有的【Linux下，用户目录没有 .profile 文件】 epoll、kqueue机制 传给脚本的参数 $# 是传给脚本的参数个数 $0 是脚本本身的名字 $1 是传递给该shell脚本的第一个参数 $2 是传递给该shell脚本的第二个参数 $@ 是传给脚本的所有参数的列表 profile 文件的执行顺序 bash 登录的时候，先执行全局的 profile 文件：&#x2F;etc&#x2F;profile 接着 bash 会检查当前用户的 home 目录中，是否有 .bash_profile 或 .bash_login 或 .profile 文件，若有，则会执行其中一个，执行顺序为：.bash_profile -&gt; .bash_login -&gt; .profile。 etc&#x2F;hosts 文件在 etc&#x2F;hosts 文件中手动配置域名和 IP 的映射，这样就可以不用 DNS 就可以解析域名了。留有疑问，我本地自定义了一个域名，并在hosts文件中配置了映射为百度的IP地址，但是就是访问不了？ Linux下安装软件的方式 工具安装。软件包管理工具有：apt、rpm、yum 等。 apt，即 advanced package tools。apt 是现今最成熟的软件包管理系统，它可以自动检测软件依赖问题，下载和安装所有文件。甚至只需要一条命令，就可以更新整个系统上所有的软件包。apt 工具最初被设计运行于 Debian 系统上，只支持 .deb 格式的软件包文件。如今 apt 工具已经被移植到使用 rpm 软件包机制的发行版 Linux 系统上，可以从 apt-rpm.org 获得 apt 的 rpm 版本。apt 工具最常用的有两个命令：apt-get：用于执行和软件包安装有关的所有操作。apt-cache：用于查找软件包的相关信息。apt 工具是 Ubuntu、Debian 下软件包管理工具。 rpm，即 redhat package manager，原本是 Red Hat Linux 发行版专门用来管理 Linux 各项套件的程序，由于它遵循 GPL 规则且功能强大方便，因而广受欢迎。逐渐受到其他 Linux 发行版的采用。 rpm 套件管理方式的出现，让 Linux 易于安装、升级，间接提升了 Linux 的适用度。rpm 此名词既可以指 .rpm 文件格式的软件包，也可以指其本身的软件包管理器。rpm 工具最早由 Red Hat 研制，现在也由开源社区开发。rpm 工具通常随附于 Linux 发行版，但也有单独将 rpm 作为应用软件发行。 rpm 包的安装有一个很大的缺点：文件的关联性太大，有时候装一个软件要安装很多其他的软件包，管理软件间关联关系很麻烦。为此 RedHat 开发了 yum 安装方法，yum 并不是一种包，而是安装包的软件。yum 可以彻底解决这个关联性的问题，很方便，只要配置两个文件即可安装，安装方法是： 简单点说，rpm 只能安装已经下载到本地机器上的 rpm 包。yum 能从指定服务器在线下载并安装 rpm 包，还能更新系统，且还能自动处理包与包之间的依赖问题，这个是 rpm 工具所不具备的。 rpm &amp; tarrpm 一般都是预先编译好的文件，它可能已经绑定到某种 CPU 或者 Linux 发行版上面了。tar 一般包括编译脚本，你可以在你的环境下编译，所以具有通用性；tar 只是一种压缩文件格式，一般都是软件的源码打包成的，需要自己解包，然后进行安装三部曲 ./configure, make, make install 来安装软件。如果你的包不想开放源代码，你可以制作成 rpm，如果开源，用 tar 更方便。 yum 工具是 CentOS、Redhat 下的软件包管理工具。 源代码安装。源代码压缩文件包的格式后缀可以是：.tar、tar.gz、tar.bz2、tar.Z。解压好源代码压缩文件后，一般依次执行如下的命令： 二进制文件安装。二进制文件是机器能直接执行的文件，二进制包的安装比较简单，我们需要做的只是将从网络上下载的二进制包解压后放到合适的目录，然后将包含可执行的主程序文件的目录添加进PATH环境变量即可。 文件属性Linux系统中，文件属性“l”是链接文件，相当于windows的快捷方式; “b”是块设备,硬盘就是一个例子; “c”是字符设备文件,鼠标,键盘算是; “d”是目录文件,相当于windows的文件夹； 硬连接和软连接Linux 链接分两种，一种被称为硬链接（Hard Link），另一种被称为符号链接（Symbolic Link）。默认情况下，ln 命令产生硬链接。硬连接硬连接指通过索引节点来进行连接。在 Linux 的文件系统中，保存在磁盘分区中的文件不管是什么类型都给它分配一个编号，称为索引节点号(Inode Index)。在 Linux 中，多个文件名指向同一索引节点是存在的。比如：A 是 B 的硬链接（A 和 B 都是文件名），则 A 的目录项中的 inode 节点号与 B 的目录项中的 inode 节点号相同，即一个 inode 节点对应两个不同的文件名，两个文件名指向同一个文件，A 和 B 对文件系统来说是完全平等的。删除其中任何一个都不会影响另外一个的访问。硬连接的作用是允许一个文件拥有多个有效路径名，这样用户就可以建立硬连接到重要文件，以防止“误删”的功能。其原因如上所述，因为对应该目录的索引节点有一个以上的连接。只删除一个连接并不影响索引节点本身和其它的连接，只有当最后一个连接被删除后，文件的数据块及目录的连接才会被释放。也就是说，文件真正删除的条件是与之相关的所有硬连接文件均被删除。软连接另外一种连接称之为符号连接（Symbolic Link），也叫软连接。软链接文件有类似于 Windows 的快捷方式。它实际上是一个特殊的文件。在符号连接中，文件实际上是一个文本文件，其中包含的有另一文件的位置信息。比如：A 是 B 的软链接（A 和 B 都是文件名），A 的目录项中的 inode 节点号与 B 的目录项中的 inode 节点号不相同，A 和 B 指向的是两个不同的 inode，继而指向两块不同的数据块。但是 A 的数据块中存放的只是 B 的路径名（可以根据这个找到 B 的目录项）。A 和 B 之间是“主从”关系，如果 B 被删除了，A 仍然存在（因为两个是不同的文件），但指向的是一个无效的链接。 删除符号连接f3，对f1、f2无影响； 删除硬连接f2，对f1、f3也无影响； 删除原文件f1，对硬连接f2没有影响，而符号连接f3失效； 同时删除原文件f1，硬连接f2，整个文件会真正的被删除。 firewall 和阿里云 ECS 的安全组的关系？阿里云的安全组是一种虚拟防火墙，具有状态检测和数据包过滤的功能。控制台安全组放行某个端口，只能说明安全组没有限制这个端口的访问，不能说明这个端口已经开启。如需外网访问 ECS 服务器的端口需要满足以下三个必要条件： 安全组规则放行该端口； 对应端口的程序软件是启动运行状态，并且监听地址为 0.0.0.0（您可通过执行 netstat -ano | grep 端口号命令来检测端口是否处于监听状态）； 已关闭 ECS 实例内部防火墙firewall，或者防火墙firewall已放行该端口； 内核 &amp; Shell &amp; 终端模拟器管理计算机硬件的其实是内核，而用户通过 Shell 来与计算机的内核通信。Shell 是一个用 C 语言编写的程序，它是用户使用 Linux 的桥梁。Shell 是指一种应用程序，这个应用程序提供了一个界面，用户通过这个界面访问操作系统内核的服务。Ken Thompson 的 sh 是第一种 Unix Shell，Windows Explorer 是一个典型的图形界面 Shell。Shell 本质上就是能执行各种命令的宏处理器，而 bash(&#x2F;bin&#x2F;bash) 是 Linux 系统默认的 shell。如果是不带有图形环境的 Linux 系统（比如专用于服务器的系统），启动后就直接是命令行环境。不过，现在大部分的 Linux 发行版，尤其是针对普通用户的发行版，都是图形环境。用户登录系统后，自动进入图形环境，需要自己启动终端模拟器，才能进入命令行环境。所谓“终端模拟器”（terminal emulator）就是一个模拟命令行窗口的程序，让用户在一个窗口中使用命令行环境，并且提供各种附加功能，比如调整颜色、字体大小、行距等等。不同 Linux 发行版（准确地说是不同的桌面环境）带有的终端程序是不一样的，比如 KDE 桌面环境的终端程序是 konsole，Gnome 桌面环境的终端程序是 gnome-terminal，用户也可以安装第三方的终端程序。所有终端程序，尽管名字不同，基本功能都是一样的，就是让用户可以进入命令行环境，使用 Shell。 更多 bash 用法见文档链接 CPU cpi全称为 clock cycle per instruction，即每条计算机指令执行所需的 cpu 时钟周期。 cpu 时钟周期是一个时钟脉冲所需要的时间，也叫节拍脉冲或 T 周期，它是 cpu 中最小的时间单位。 脉冲通常是指电子技术中经常运用的一种像脉搏似的短暂起伏的电冲击(电压或电流)。 主要特性有波形、幅度、宽度和重复频率。 脉冲是相对于连续信号在整个信号周期内短时间发生的信号，大部分信号周期内没有信号。 就像人的脉搏一样。 cpu 时钟频率也叫主频，是 1 秒钟内的时钟脉冲个数，即 cpu 时钟周期的倒数。 cpu 执行时间运行一个程序所需要的 cpu 执行时间 &#x3D; 总时钟周期数 &#x2F; 主频 &#x3D; 总指令条数 * cpi &#x2F; 主频。 相关概念——物理 cpu 数（Socket）、核心core、thread（1）物理 cpu 数主板上实际插入的 cpu 硬件个数（socket），由于在主板上引入多个 cpu 插槽需要更复杂的硬件支持（连接不同插槽的 cpu 到内存和其他资源），通常只会在服务器上才这样做，在家用电脑中，一般主板上只会有一个 cpu 插槽。（2）核心 core起初，每个物理 cpu 上只有一个核心 core，对操作系统而言，也就是同一时刻只能运行一个进程&#x2F;线程。 为了提高性能，cpu 厂商开始在单个物理 cpu 上增加核心（实实在在的硬件存在），也就出现了双核心 cpu 以及多核心 cpu。双核心 cpu 也就是同一时刻能够运行两个进程&#x2F;线程的 cpu。（3）同时多线程技术（simultaneous multithreading）和 超线程技术（hyper–threading&#x2F;HT）本质同样是为了提高单个 core 同一时刻能够执行的多线程数的技术，充分利用单个 core 的计算能力，尽量让其”一刻也不得闲”。simultaneous multithreading 缩写是 SMT，是 AMD 和其他 cpu 厂商的称呼。 hyper–threading 是 Intel 的称呼，也可以认为 hyper–threading 是 SMT 的一种具体技术实现。 Linux下查看 cpu 的信息 centos 系统下删除 mysql 及 mysqld。先利用 rpm 找出所有的 sql 相关的文件：Rpm -q -a | grep sql然后利用rpm删除找到的文件：Rpm -e … Poller 的 fd 集合 部分编译器下，比如gcc， 两个long合用,即long long类型，表示C语言目前最长的系统整型类型，每个long long类型占8字节，64位。其格式化字符为”%lld”。 Source 设置环境变量只在当前 shell 窗口下生效，重新打开一个窗口要重新 source setenv.sh 而且要注意直接 .&#x2F; 执行和 source 执行的差别。 UINT64_MAX 再增加的溢出问题；例如 UINT64_MAX + 常数，就会产生溢出问题，得到意想不到的结果或直接报错。 常用的环境变量如下： PATH 决定了 shell 将到哪些目录中寻找命令或程序 HOME 当前用户主目录 HISTSIZE 历史记录数 LOGNAME 当前用户的登录名 HOSTNAME 指主机的名称 SHELL 当前用户Shell类型 LANGUGE 语言相关的环境变量，多语言可以修改此环境变量 MAIL 当前用户的邮件存放目录 PS1 基本提示符，对于root用户是＃，对于普通用户是＄ SSHSSH 只是一种协议，存在多种实现，既有商业实现，也有开源实现。本人用的是开源自由实现 OpenSSH。 SSH 密码登录 &amp; 公钥登录。加上 -v -l pi 可以将连接时候的日志都打印出来。见公钥登录 SSH 远程连接时，报错”ssh_exchange_identification: Connection closed by remote host”，可能原因如下。（1）远程主机启用了 DenyHosts 服务。如果远程主机安装了 DenyHosts 服务，需要查看远程主机 &#x2F;etc&#x2F;hosts.deny 文件是否有本机的记录，如有则将记录删除，并执行如下命令重启 sshd 和 rsyslog 服务。 （2）客户端连接数过多。缺省情况下，SSH终端连接个数最大为 10，这种情况下，需要修改 SSH 的配置文件并重启 SSHD。 mac 添加 ssh config 配置，快速登录 linux 系统。（1）访问根目录下 .ssh 文件夹并通过如下命令生成本机的 id_rsa（私钥）与 id_rsa.pub（公钥）文件。 （2）创建并编辑配置文件 config。 （3）在远程主机的目标用户根目录下的 .ssh 文件目录下创建文件 authorized_keys，已有则忽略；并追加本机公钥内容。 stdin &amp; stdoutLinux下，当一个用户进程被创建的时候，系统会自动为该进程创建三个数据流，分别为 stdin、stdout、stderr。 符号 &gt; 可以将程序的标准输出 stdout 重定向到文件中。 符号 &lt; 将程序的标准输入重定向为从文件输入。 执行当前工作目录中的 program 时还是老老实实的 .&#x2F;program 这样执行当前工作目录 .&#x2F; 一般并未在搜索范围之列，也就是 PATH 环境变量的值中并不包含 .&#x2F; 这个当前工作目录。为什么一般不能加入这个当前工作目录呢？主要原因在于安全问题。试想，一个evil 用户在自己的家目录 &#x2F;home&#x2F;evil&#x2F; 中放了一个名字叫ls的程序，当root用户或其它用户来到这个&#x2F;home&#x2F;evil&#x2F;目录时，想查看这个目录中有些啥子文件，于是执行ls命令，这时如果.&#x2F;目录在PATH环境变量中且搜索时先搜索这个.&#x2F;目录的话，则执行到的程序是&#x2F;home&#x2F;evil&#x2F;ls而不是&#x2F;bin&#x2F;ls程序，这样就会造成极大地安全问题。 Linux 上进程有 5 种状态：运行（正在运行或在运行队列中等待）中断（休眠中，受阻，在等待某个条件的形成或接受到信号）不可中断（收到信号不唤醒和不可运行，进程必须等待直到有中断发生）僵死（进程已终止, 但进程描述符存在, 直到父进程调用 wait4() 系统调用后释放）停止（进程收到 SIGSTOP、SIGSTP、SIGTIN、SIGTOU 信号后停止运行） BSD 格式和 SystemV 格式 SSD HMB 和 CMB 2. 命令2.1. 阅览｜筛选文件内容 2.2. 查看当前的操作系统信息【CentOS】 2.3. 输出某个目录下所有内容 2.4. 控制用户对文件的权限chmod 全称是 change mode，该命令是控制用户对文件的权限的命令，Linux&#x2F;Unix 的文件调用权限分为三级: 文件所有者（Owner）、用户组（Group）、其它用户（Other Users），只有文件所有者和超级用户可以修改文件或目录的权限，可以使用如下两种模式指定文件的权限。 符号模式 绝对模式（八进制数字模式） 2.5. 定时任务 例如可以使用 crontab 定时执行某 shell 脚本，但是可能会出现 shell 脚本无法执行问题，具体情况如下。如果我们使用 crontab 来定时执行脚本，无法执行，但是直接通过命令（如：.／test.sh）又可以正常执行，这主要是因为无法读取环境变量。解决方法： 所有命令需要写成绝对路径形式，如：&#x2F;usr&#x2F;local&#x2F;bin&#x2F;docker。 在 shell 脚本开头使用以下代码： 在 &#x2F;etc&#x2F;crontab 中添加环境变量，在可执行命令之前添加命令 . /etc/profile;/bin/sh，使得环境变量生效。 2.6. 查看机器的硬件情况 2.7. 删除文件｜文件夹 2.8. 用户操作 2.9. 压缩｜显示内容｜解压 tar &amp; tar.gz 文件 2.10. 查找文件｜文件夹 2.11. 显示目前资源限制的设定 2.12. NetcatNetcat 是一款简单的 Unix 工具，是一个功能强大的网络工具，使用 UDP 和 TCP 协议。 它是一个可靠的容易被其他程序所启用的后台操作工具； 同时它也被用作网络的测试工具或黑客工具。使用它你可以轻易的建立任何连接。内建有很多实用的工具。 2.13. 复制文件和目录 2.14. 显示电脑以及操作系统信息 2.15. 端口 2.16. 显示系统中已存在的环境变量 2.17. 文件追加内容 2.18. 建立软链接 2.19. 查看软件的安装路径 2.20. sudo 权限管理 2.21. su 切换用户 2.22. psLinux 中的 ps 命令是 Process Status 的缩写。ps 命令用来列出系统中当前运行的进程，提供进程信息的一次性查看。ps 命令列出的是当前那些进程的快照，就是执行 ps 命令的那个时刻的进程，如果想要动态的显示进程信息，就可以使用 top 命令。 ps 工具标识进程的5种状态码: D 不可中断 uninterruptible sleep (usually IO) R 运行 runnable (on run queue) S 中断 sleeping T 停止 traced or stopped Z 僵死 a defunct (“zombie”) process ps 命令参数 aux 和 -efps aux 可以列出所有的正在运行的进程，最近发现还是有些缺陷，用 ps aux 和 ps -ef 得到的结果居然不一样，以后尽量用 -ef 参数吧。例如，用/bmrt/blaph/blaph/bmgctl来启动进程，由于 ps aux 是用 BSD 格式来显示结果，所以 ps aux | grep bmgctl 可能只会显示到 /bmrt/blaph/blaph，后面的会被截掉。这样，如果用 ps aux | grep bmgctl 来过滤该进程，可能就会误伤，获取不到 bmgctl 进程。而 ps -ef 是用全格式的 System V 格式来显示结果的，显示的就是带全路径的进程名，会显示出 bmgctl，使用 ps -ef | grep bmgctl 命令就可以完整显示该进程了。 2.23. jps很多人都用过 Unix 系统里的 ps 命令，ps 命令主要是用来显示当前系统的进程情况，例如有哪些进程以及进程 pid。jps，全称 Java Virtual Machine Process Status Tool，即 Java 虚拟机进程状态工具。jps 是 jdk 提供的一个查看当前 java 进程的小工具，能够显示当前所有 java 进程的 pid，适合在 linux&#x2F;unix 平台上简单查看当前 java 进程的一些简单情况。我们可以通过 jps 命令来查看我们到底启动了多少个 java 进程（因为每一个 java 程序都会独占一个 JVM 实例）。 2.24. firewall 2.25. 查询 DNS 的记录 2.26. tmux 工具tmux 是一个终端复用器（terminal multiplexer），属于常用的开发工具。命令行的典型使用方式是，打开一个终端窗口（terminal window，以下简称”窗口”），在里面输入命令。用户与计算机的这种临时的交互，称为一次”会话”（session） 。会话的一个重要特点是，窗口与其中启动的进程是连在一起的：打开窗口，会话开始；关闭窗口，会话结束，会话内部的进程也会随之终止，不管有没有运行完。一个典型的例子就是，SSH 登录远程计算机，打开一个远程窗口执行命令，如果网络突然断线，再次登录是找不回上一次执行的命令的，因为上一次 SSH 会话已经终止了，里面的进程也随之消失了。为了解决这个问题，会话与窗口可以【解绑】：窗口关闭时，会话并不终止，而是继续运行，等到以后需要的时候，再让会话【绑定】其他窗口。Tmux 就是会话与窗口的【解绑】工具，将它们彻底分离。 它允许在单个窗口中，同时访问多个会话，这对于同时运行多个命令行程序很有用。 它可以让新窗口”接入”已经存在的会话。 它允许每个会话有多个连接窗口，因此可以多人实时共享会话。 它还支持窗口任意的垂直和水平拆分。类似的终端复用器还有 GNU Screen。Tmux 与它功能相似，但是更易用，也更强大。以下是命令行交互命令： 键盘快捷键 更多用法见Tmux教程 2.27. kill 2.28. mv 移动包 2.29. nohup 2.30. 管道输出 –stdin这个选项用于从标准输入管道读入新的密码。 2.31. seq命令seq 是 sequence 的缩写，主要用来产生整数序列。 2.32. xargs命令xargs(extended arguments)，是给命令传递参数的一个过滤器，也是组合多个命令的一个工具。xargs 可以将管道或标准输入（stdin）数据转换成命令行参数，也能够从文件的输出中读取数据。xargs 也可以将单行或多行文本输入转换为其他格式，例如多行变单行，单行变多行。xargs 默认的命令是 echo，这意味着通过管道传递给 xargs 的输入将会包含换行和空白，不过通过 xargs 的处理，换行和空白将被空格取代。xargs 是一个强有力的命令，它能够捕获一个命令的输出，然后传递给另外一个命令。之所以能用到这个命令，关键是由于很多命令不支持 | 管道来传递参数，而日常工作中有有这个必要，所以就有了 xargs 命令，例如： xargs 一般是和管道 | 一起使用。 参数含义： -i 或者是 -I，这得看linux支持了，将 xargs 的每项名称，一般是一行一行赋值给 {}，可以用 {} 代替。 -i 是默认使用大括号 {} 作为替换符号，而 -I 则可以自定义其他符号、字母、数字、字符串作为替换符号，但需要使用引号引起来。通常使用 -i 选项，因为简单，但如果要接收的命令中已经使用了大括号 {}（如 touch {1..100}.txt），那么就不能使用 -i 选项了，需要使用 -I 选项。 -L num，从标准输入一次读取 num 行送给 command 命令。 -l 同 -L。例如： 2.33. dd命令Linux dd 命令用于读取、转换并输出数据。dd 可从标准输入或文件中读取数据，根据指定的格式来转换数据，再输出到文件、设备或标准输出。 参数含义： if&#x3D;文件名：输入文件名，默认为标准输入，即指定源文件。 of&#x3D;文件名：输出文件名，默认为标准输出，即指定目的文件。 ibs&#x3D;bytes：一次读入bytes个字节，即指定一个块大小为bytes个字节。 obs&#x3D;bytes：一次输出bytes个字节，即指定一个块大小为bytes个字节。 bs&#x3D;bytes：同时设置读入&#x2F;输出的块大小为bytes个字节。 count&#x3D;blocks：仅拷贝blocks个块，块大小等于ibs指定的字节数。 2.34. wc命令wc 命令用于计算字数，利用 wc 指令我们可以计算文件的 Byte 数、字数、或是行数。若不指定文件名称，或是所给予的文件名为”-“，则 wc 指令会从标准输入设备读取数据。 参数含义： -c 或 –bytes 或 –chars 只显示 Bytes 数。 -l 或 –lines 显示行数。 -w 或 –words 只显示字数。 2.35. 网口Linux ip 命令与 ifconfig 命令类似，但比 ifconfig 命令更加强大，主要功能是用于显示或设置网络设备。ip 命令是 Linux 加强版的的网络配置工具，用于代替 ifconfig 命令。 2.35.1. 网络带宽单位10GE&#x2F;s 2.35.2. 网络设备的物理接口类型光口和电口是计算机网络中常用的术语，用于描述网络设备的物理接口类型。它们的区别在于数据传输的方式是通过光信号还是电信号。光口（Optical port）是指通过光纤传输数据的接口，它使用光纤作为传输介质，利用光的反射和折射进行信号的传输。光口可以分为单模光口（Single-mode optical port）和多模光口（Multimode optical port），单模光口适用于长距离的光纤传输，多模光口适用于短距离的光纤传输。电口（Electrical port）是指通过电缆传输数据的接口，它使用电信号作为传输介质，利用电流的变化进行信号的传输。电口可以分为RJ45电口和SFP电口，RJ45电口适用于局域网的连接，SFP电口适用于远程网络设备的连接。在网络设备中，光口和电口通常可以互相转换，以便在不同的网络环境中进行连接。例如，可以使用光口转换器【光模块】将光口转换为电口，以便连接到局域网中的设备。另外，一些网络设备也可以同时支持光口和电口，以便在不同的传输介质中进行选择。 2.36. 命令行快捷键 2.38. 交换空间Swap 2.39. 内存在 Linux 上如何清除内存的 Cache、Buffer 和交换空间 内核是如何管理内存的？ Linux内存占用分析的几个方法？ 2.39.1. 内存数据页内存数据页（Memory page）是计算机中管理和分配内存的基本单位。在操作系统中，内存被分割成多个数据页，每个页的大小通常为4KB或者更大。每个数据页都有一个唯一的标识符，称为页框号（Page Frame Number, PFN），用于在物理内存中定位该页的位置。当程序需要访问内存中的数据时，如果程序需要访问的数据不在物理内存中，操作系统会触发一个缺页异常，将该页从磁盘中读取到物理内存中，然后再将数据返回给程序。内存数据页的大小对计算机的性能和内存管理有着重要的影响，在选择数据页大小时需要权衡各种因素，根据具体的应用场景和硬件平台来进行选择。 过小的页面大小会带来较大的页表项，增加寻址时 TLB（Translation lookaside buffer）的查找时间和额外开销； 过大的页面大小会浪费内存空间，造成内存碎片，降低内存的利用率； 2.39.2.查看页大小 TLB: 2.40. sar命令2.41. 时钟同步linux 时间同步，ntpd、ntpdate 命令系统时间&#x2F;硬件时间"}]